{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f1a2245",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import genova\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from collections import OrderedDict\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83323c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genova.utils.BasicClass import Ion, Residual_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b1c253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4593a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genova/utils/dictionary') as f:\n",
    "    dictionary = json.load(f)\n",
    "reverse_dictionary = {idx:aa for aa, idx in dictionary.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc04c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')\n",
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[spec_header['Experiment Name']=='PXD008844']\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]\n",
    "dataset = genova.data.GenovaDataset(cfg,dictionary=dictionary,spec_header=small_spec,dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn  = genova.data.GenovaCollator(cfg,mode='eval')\n",
    "dl = DataLoader(dataset,batch_size=1,collate_fn=collate_fn)\n",
    "model = genova.models.Genova(cfg).cuda()\n",
    "checkpoint = torch.load('/data/z37mao/save/Genova_model.pt',map_location = {'cuda:%d' % 0: 'cuda:%d' % 1})\n",
    "model.load_state_dict(OrderedDict([(k[7:],v) for k,v in checkpoint['model_state_dict'].items()]))\n",
    "model = model.eval()\n",
    "for p in model.parameters():\n",
    "    p.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f42c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_input_cuda(encoder_input):\n",
    "    for section_key in encoder_input:\n",
    "        for key in encoder_input[section_key]:\n",
    "            if isinstance(encoder_input[section_key][key],torch.Tensor):\n",
    "                encoder_input[section_key][key] = encoder_input[section_key][key].cuda()\n",
    "    return encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0db4b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search(memory,i):\n",
    "    k = beam_size\n",
    "    tgt_index = torch.full((1,1),dictionary['<n_term>']).cuda()\n",
    "    output = model.output_ffn(model.decoder(tgt_index=tgt_index, memory=memory))\n",
    "    perplexity = torch.log_softmax(output[:,-1],-1)\n",
    "    perplexity, aa_index = torch.topk(perplexity, k, dim=-1)\n",
    "    perplexity = perplexity.view(-1,1)\n",
    "    aa_index = aa_index.view(-1,1)\n",
    "    tgt_index = torch.concat([tgt_index.repeat(k,1),aa_index],dim=-1)\n",
    "    \n",
    "    done_pep = []\n",
    "    done_perplexity = []\n",
    "    \n",
    "    charge, precursor_mz = small_spec[['Charge','m/z [Da]']].iloc[i]\n",
    "\n",
    "    seq_len = 1\n",
    "    while k>0 and seq_len<100:\n",
    "        probability = model.output_ffn(model.decoder(tgt_index=tgt_index, \n",
    "                                                     memory=torch.repeat_interleave(memory,tgt_index.size(0),dim=0)))[:,-1,:]\n",
    "        probability = torch.log_softmax(probability,-1)\n",
    "        perplexity = perplexity + probability\n",
    "        perplexity = perplexity.view(1,-1)\n",
    "        perplexity, aa_index = torch.topk(perplexity,k)\n",
    "        aa = aa_index%30\n",
    "        tgt_index = tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)]\n",
    "        perplexity = perplexity.view(-1,1)\n",
    "        tgt_index = torch.concat([tgt_index,aa.view(-1,1)],dim=-1)\n",
    "        done_mask = aa.squeeze(0)==dictionary['<c_term>']\n",
    "        seq_len+=1\n",
    "        if done_mask.sum()>0:\n",
    "            k-=done_mask.sum()\n",
    "            done_pep.append(tgt_index[done_mask].cpu())\n",
    "            done_perplexity.append(perplexity[done_mask].cpu())\n",
    "            perplexity = perplexity[~done_mask]\n",
    "            tgt_index = tgt_index[~done_mask]\n",
    "    if k>0:\n",
    "        done_pep.append(pad(tgt_index,(0,1)).cpu())\n",
    "        done_perplexity.append(perplexity.cpu())\n",
    "\n",
    "    seqs = []\n",
    "    for seq_group in done_pep:\n",
    "        for seq_index in seq_group:\n",
    "            seqs.append(''.join([reverse_dictionary[i] for i in seq_index[1:-1].numpy()]))\n",
    "    done_perplexity = torch.concat(done_perplexity).squeeze(1).numpy()\n",
    "    seqs = np.array(seqs)[np.argsort(-done_perplexity)]\n",
    "    done_perplexity = -np.sort(-done_perplexity)\n",
    "    precursor_mass = Ion.precursorion2mass(precursor_mz, charge)\n",
    "    seq_mass = np.array([Residual_seq(seq).mass for seq in seqs])\n",
    "    mass_mask = np.abs(seq_mass-precursor_mass)/precursor_mass<10e-6\n",
    "    if mass_mask.sum()>0:\n",
    "        done_perplexity = done_perplexity[mass_mask]\n",
    "        seqs=seqs[mass_mask]\n",
    "    return seqs, np.exp(done_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4261fa82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_AA_novor(target, predicted):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    #~ print(\"\".join([\"=\"] * 80)) # section-separating line\n",
    "    #~ print(\"WorkerTest._test_AA_match_novor()\")\n",
    "\n",
    "    num_match = 0\n",
    "    target_len = len(target)\n",
    "    predicted_len = len(predicted)\n",
    "    target_mass = np.array([Residual_seq(aa).mass for aa in target])\n",
    "    target_mass_cum = np.cumsum(target_mass)\n",
    "    predicted_mass = np.array([Residual_seq(aa).mass for aa in predicted])\n",
    "    predicted_mass_cum = np.cumsum(predicted_mass)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < target_len and j < predicted_len:\n",
    "        if abs(target_mass_cum[i] - predicted_mass_cum[j]) < 0.5:\n",
    "            if abs(target_mass[i] - predicted_mass[j]) < 0.1:\n",
    "            #~ if  decoder_input[index_aa] == output[index_aa]:\n",
    "              num_match += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif target_mass_cum[i] < predicted_mass_cum[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "    return num_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fa3e966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "153044c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_size = 30\n",
    "right_aa = 0\n",
    "right_peptide = 0\n",
    "for i, (encoder_input, node_mask, labels) in enumerate(dl):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    label = small_spec['Annotated Sequence'].iloc[i]\n",
    "    memory = model.encoder(**encoder_input)\n",
    "    predicted_seqs, probability = beam_search(memory,i)\n",
    "    if predicted_seqs[0]==label.replace('L','I'): right_peptide+=1\n",
    "    #else: print(i)\n",
    "    if i==15: break\n",
    "    #break\n",
    "    right_aa += match_AA_novor(label.replace('L','I'),predicted_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "931bbaa7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'KEIDAINGEVEGQQEEQETQEK'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cda9f80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256.11715501168004"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Residual_seq('QQ').mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f265cb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "257.13755610394"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Residual_seq('KE').mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80afa7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_seqs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ceb8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "label.replace('L','I')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144ec7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = beam_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50edf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_index = torch.full((1,1),dictionary['<n_term>']).cuda()\n",
    "output = model.output_ffn(model.decoder(tgt_index=tgt_index, memory=memory))\n",
    "perplexity = torch.log_softmax(output[:,-1],-1)\n",
    "perplexity, aa_index = torch.topk(perplexity, k, dim=-1)\n",
    "perplexity = perplexity.view(-1,1)\n",
    "aa_index = aa_index.view(-1,1)\n",
    "tgt_index = torch.concat([tgt_index.repeat(k,1),aa_index],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745219ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_pep = []\n",
    "done_perplexity = []\n",
    "charge, precursor_mz = small_spec[['Charge','m/z [Da]']].iloc[i]\n",
    "    \n",
    "probability = model.output_ffn(model.decoder(tgt_index=tgt_index, \n",
    "                                                 memory=torch.repeat_interleave(memory,tgt_index.size(0),dim=0)))[:,-1,:]\n",
    "probability = torch.log_softmax(probability,-1)\n",
    "perplexity = perplexity + probability\n",
    "perplexity = perplexity.view(1,-1)\n",
    "perplexity, aa_index = torch.topk(perplexity,k)\n",
    "aa = aa_index%30\n",
    "tgt_index = tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)]\n",
    "perplexity = perplexity.view(-1,1)\n",
    "tgt_index = torch.concat([tgt_index,aa.view(-1,1)],dim=-1)\n",
    "done_mask = aa.squeeze(0)==dictionary['<c_term>']\n",
    "print(tgt_index)\n",
    "if done_mask.sum()>0:\n",
    "    k-=done_mask.sum()\n",
    "    done_pep.append(tgt_index[done_mask].cpu())\n",
    "    done_perplexity.append(perplexity[done_mask].cpu())\n",
    "    perplexity = perplexity[~done_mask]\n",
    "    tgt_index = tgt_index[~done_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e80bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = beam_size\n",
    "tgt_index = torch.full((1,1),dictionary['<n_term>']).cuda()\n",
    "output = model.output_ffn(model.decoder(tgt_index=tgt_index, memory=memory))\n",
    "perplexity = torch.log_softmax(output[:,-1],-1)\n",
    "perplexity, aa_index = torch.topk(perplexity, k, dim=-1)\n",
    "perplexity = perplexity.view(-1,1)\n",
    "aa_index = aa_index.view(-1,1)\n",
    "tgt_index = torch.concat([tgt_index.repeat(k,1),aa_index],dim=-1)\n",
    "\n",
    "done_pep = []\n",
    "done_perplexity = []\n",
    "\n",
    "charge, precursor_mz = small_spec[['Charge','m/z [Da]']].iloc[i]\n",
    "\n",
    "seq_len = 1\n",
    "while k>0 and seq_len<100:\n",
    "    probability = model.output_ffn(model.decoder(tgt_index=tgt_index, \n",
    "                                                 memory=torch.repeat_interleave(memory,tgt_index.size(0),dim=0)))[:,-1,:]\n",
    "    probability = torch.log_softmax(probability,-1)\n",
    "    perplexity = perplexity + probability\n",
    "    perplexity = perplexity.view(1,-1)\n",
    "    perplexity, aa_index = torch.topk(perplexity,k)\n",
    "    aa = aa_index%30\n",
    "    tgt_index = tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)]\n",
    "    perplexity = perplexity.view(-1,1)\n",
    "    tgt_index = torch.concat([tgt_index,aa.view(-1,1)],dim=-1)\n",
    "    done_mask = aa.squeeze(0)==dictionary['<c_term>']\n",
    "    if done_mask.sum()>0:\n",
    "        k-=done_mask.sum()\n",
    "        done_pep.append(tgt_index[done_mask].cpu())\n",
    "        done_perplexity.append(perplexity[done_mask].cpu())\n",
    "        perplexity = perplexity[~done_mask]\n",
    "        tgt_index = tgt_index[~done_mask]\n",
    "    seq_len+=1\n",
    "    if k!=0:\n",
    "        done_pep.append(pad(tgt_index,(0,1)).cpu())\n",
    "        done_perplexity.append(perplexity.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b174cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adb3a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad(tgt_index,(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059a7985",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dac568",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = []\n",
    "for seq_group in done_pep:\n",
    "    for seq_index in seq_group:\n",
    "        seqs.append(''.join([reverse_dictionary[i] for i in seq_index[1:-1].numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f689d1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb0e4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_pep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe3ac73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a114f457",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_pep = []\n",
    "done_perplexity = []\n",
    "\n",
    "while k>0:\n",
    "    probability = model.output_ffn(model.decoder(tgt_index=tgt_index, \n",
    "                                                 memory=torch.repeat_interleave(memory,tgt_index.size(0),dim=0)))[:,-1,:]\n",
    "    probability = torch.log_softmax(probability,-1)\n",
    "    perplexity = perplexity + probability\n",
    "    perplexity = perplexity.view(1,-1)\n",
    "    perplexity, aa_index = torch.topk(perplexity,k)\n",
    "    aa = aa_index%30\n",
    "    tgt_index = tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)]\n",
    "    perplexity = perplexity.view(-1,1)\n",
    "    tgt_index = torch.concat([tgt_index,aa.view(-1,1)],dim=-1)\n",
    "    done_mask = aa.squeeze(0)==dictionary['<c_term>']\n",
    "    if done_mask.sum()>0:\n",
    "        k-=done_mask.sum()\n",
    "        done_pep.append(tgt_index[done_mask].cpu())\n",
    "        done_perplexity.append(perplexity[done_mask].cpu())\n",
    "        perplexity = perplexity[~done_mask]\n",
    "        tgt_index = tgt_index[~done_mask]\n",
    "        \n",
    "seqs = []\n",
    "for seq_group in done_pep:\n",
    "    for seq_index in seq_group:\n",
    "        seqs.append(''.join([reverse_dictionary[i] for i in seq_index[1:-1].numpy()]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ed61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67263827",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eca924",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_perplexity = torch.concat(done_perplexity).squeeze(1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4488dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs = np.array(seqs)[np.argsort(-done_perplexity)]\n",
    "done_perplexity = -np.sort(-done_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b09be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_mass = Ion.precursorion2mass(precursor_mz, charge)\n",
    "seq_mass = np.array([Residual_seq(seq).mass for seq in seqs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f68e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.abs(seq_mass-precursor_mass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534c4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa5d51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_perplexity = done_perplexity[np.abs(seq_mass-precursor_mass)/precursor_mass<10e-6]\n",
    "seqs=seqs[np.abs(seq_mass-precursor_mass)/precursor_mass<10e-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e4ac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([Residual_seq(aa).mass for aa in seqs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ac36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_AA_novor(target, predicted):\n",
    "    \"\"\"\"\"\"\n",
    "\n",
    "    #~ print(\"\".join([\"=\"] * 80)) # section-separating line\n",
    "    #~ print(\"WorkerTest._test_AA_match_novor()\")\n",
    "\n",
    "    num_match = 0\n",
    "    target_len = len(target)\n",
    "    predicted_len = len(predicted)\n",
    "    target_mass = np.array([Residual_seq(aa).mass for aa in target])\n",
    "    target_mass_cum = np.cumsum(target_mass)\n",
    "    predicted_mass = np.array([Residual_seq(aa).mass for aa in predicted])\n",
    "    predicted_mass_cum = np.cumsum(predicted_mass)\n",
    "\n",
    "    i = 0\n",
    "    j = 0\n",
    "    while i < target_len and j < predicted_len:\n",
    "        if abs(target_mass_cum[i] - predicted_mass_cum[j]) < 0.5:\n",
    "            if abs(target_mass[i] - predicted_mass[j]) < 0.1:\n",
    "            #~ if  decoder_input[index_aa] == output[index_aa]:\n",
    "              num_match += 1\n",
    "            i += 1\n",
    "            j += 1\n",
    "        elif target_mass_cum[i] < predicted_mass_cum[j]:\n",
    "            i += 1\n",
    "        else:\n",
    "            j += 1\n",
    "\n",
    "    return num_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d35f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "match_AA_novor('RIVAPPGGR','GVIVAPPGGR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1ddd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa1251a",
   "metadata": {},
   "outputs": [],
   "source": [
    "charge, precursor_mz = small_spec[['Charge','m/z [Da]']].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0402dee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Residual_seq('GV').mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbee3a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "Residual_seq('R').mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "small_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e5c686f",
   "metadata": {},
   "outputs": [],
   "source": [
    "precursor_mass = Ion.precursorion2mass(precursor_mz, charge)\n",
    "seq_mass = np.array([Residual_seq(seq).mass for seq in seqs])\n",
    "done_perplexity = done_perplexity[np.abs(seq_mass-precursor_mass)/precursor_mass<10e-6]\n",
    "seqs=seqs[np.abs(seq_mass-precursor_mass)/precursor_mass<10e-6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea28c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(done_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b953bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90708241",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe9fb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eb1104",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[list(np.argsort(-torch.concat(done_perplexity).squeeze(1).numpy()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c285cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.argsort(-torch.concat(done_perplexity).squeeze(1).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16942863",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argsort(-torch.concat(done_perplexity).squeeze(1).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a0719f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sort(done_perplexity,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa7eced",
   "metadata": {},
   "outputs": [],
   "source": [
    "''.join([reverse_dictionary[i] for i in seq[1:-1].numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe2848",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.concat(done_perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd9dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a27566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "done_id = np.argwhere((aa==dictionary['<c_term>']).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f51887",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-=done_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637fc6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338110dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argwhere((aa_index==dictionary['<c_term>']).cpu()).nelement() != 0:\n",
    "    k = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7099afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_index = tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)]\n",
    "perplexity = perplexity.view(-1,1)\n",
    "tgt_index = torch.concat([tgt_index,aa.view(-1,1)],dim=-1)\n",
    "print(tgt_index)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90595173",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa376186",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f08139",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_index==dictionary['<c_term>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de84896a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.argwhere((aa_index==dictionary['<c_term>']).cpu()).nelement() != 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fa2929",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary['<c_term>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f683a5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexity = perplexity + probability\n",
    "perplexity = perplexity.view(1,-1)\n",
    "perplexity, aa_index = torch.topk(perplexity,k)\n",
    "perplexity = perplexity.view(-1,1)\n",
    "aa_index = aa_index.view(-1)\n",
    "tgt_index = torch.concat([tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)+batch_id],(aa_index%30).view(-1,1)],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb9d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "perplexity = torch.zeros((batch_size*beam_size,1)).cuda()\n",
    "tgt_index = torch.full((batch_size*beam_size,1),21).cuda()\n",
    "batch_id = torch.repeat_interleave(torch.LongTensor([i*beam_size for i in range(batch_size)]),beam_size).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e673fd76",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.output_ffn(model.decoder(tgt_index=tgt_index, memory=memory))\n",
    "perplexity = perplexity + torch.log_softmax(output[:,-1],-1)\n",
    "perplexity, aa_index = torch.topk(perplexity, beam_size, dim=-1)\n",
    "perplexity = perplexity[::beam_size].reshape((-1,1))\n",
    "aa_index = aa_index[::beam_size].reshape((-1,1))\n",
    "tgt_index = torch.concat([tgt_index,aa_index],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff6a52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9dd9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(2,11):\n",
    "    output = model.output_ffn(model.decoder(tgt_index=tgt_index, memory=memory))[:,-1,:]\n",
    "    perplexity = perplexity + torch.log_softmax(output,-1)\n",
    "    perplexity = perplexity.view(batch_size,-1)\n",
    "    perplexity, aa_index = torch.topk(perplexity,beam_size)\n",
    "    perplexity = perplexity.view(-1,1)\n",
    "    aa_index = aa_index.view(-1)\n",
    "    tgt_index = torch.concat([tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)+batch_id],(aa_index%30).view(-1,1)],dim=-1)\n",
    "print(tgt_index)\n",
    "print(torch.exp(perplexity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab608f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e9938f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model.output_ffn(model.decoder(memory_key_padding_mask=node_mask, tgt_index=tgt_index, memory=memory))[:,-1]\n",
    "perplexity = perplexity + torch.log_softmax(output,-1)\n",
    "perplexity = perplexity.view(batch_size,-1)\n",
    "perplexity, aa_index = torch.topk(perplexity,beam_size)\n",
    "perplexity = perplexity.view(-1,1)\n",
    "aa_index = aa_index.view(-1)\n",
    "tgt_index = torch.concat([tgt_index[torch.div(aa_index, 30, rounding_mode='floor').view(-1)+batch_id],(aa_index%30).view(-1,1)],dim=-1)\n",
    "print(tgt_index)\n",
    "print(perplexity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b958ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145f2ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
