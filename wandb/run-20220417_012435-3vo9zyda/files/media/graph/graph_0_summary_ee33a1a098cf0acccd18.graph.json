{"format": "torch", "nodes": [{"name": "encoder", "id": 140243400659056, "class_name": "GenovaEncoder(\n  (node_encoder): NodeEncoder(\n    (ion_source_embed): Embedding(25, 54, padding_idx=0)\n    (charge_embed): Embedding(20, 1024)\n    (shared_mlp): Sequential(\n      (0): Linear(in_features=64, out_features=128, bias=True)\n      (1): ReLU(inplace=True)\n      (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n      (3): Linear(in_features=128, out_features=256, bias=True)\n      (4): ReLU(inplace=True)\n      (5): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (6): Linear(in_features=256, out_features=512, bias=True)\n      (7): ReLU(inplace=True)\n      (8): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (9): Linear(in_features=512, out_features=1024, bias=True)\n    )\n    (fc): Sequential(\n      (0): ReLU(inplace=True)\n      (1): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (2): Linear(in_features=1024, out_features=1024, bias=True)\n      (3): ReLU(inplace=True)\n      (4): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (5): Linear(in_features=1024, out_features=1024, bias=True)\n      (6): ReLU(inplace=True)\n      (7): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n      (8): Linear(in_features=1024, out_features=1024, bias=True)\n    )\n  )\n  (path_encoder): EdgeEncoder(\n    (edge_type_embed): Embedding(50150, 63, padding_idx=0)\n    (edge_pos_embed): Embedding(100, 64)\n    (dist_embed): Embedding(100, 512, padding_idx=0)\n    (mlp): Sequential(\n      (0): Linear(in_features=64, out_features=128, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=128, out_features=256, bias=True)\n      (3): ReLU(inplace=True)\n      (4): Linear(in_features=256, out_features=512, bias=True)\n    )\n    (fc): Sequential(\n      (0): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      (1): Linear(in_features=512, out_features=256, bias=True)\n      (2): ReLU(inplace=True)\n      (3): Linear(in_features=256, out_features=256, bias=True)\n    )\n  )\n  (edge_encoder): EdgeEncoder(\n    (edge_type_embed): Embedding(50150, 31, padding_idx=0)\n    (mlp): Sequential(\n      (0): Linear(in_features=32, out_features=64, bias=True)\n      (1): ReLU(inplace=True)\n      (2): Linear(in_features=64, out_features=256, bias=True)\n    )\n    (fc): Sequential(\n      (0): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (1): Linear(in_features=256, out_features=256, bias=True)\n      (2): ReLU(inplace=True)\n      (3): Linear(in_features=256, out_features=256, bias=True)\n    )\n  )\n  (genova_encoder_layers): ModuleList(\n    (0): GenovaEncoderLayer(\n      (relation): Relation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (linear_edge): Linear(in_features=256, out_features=256, bias=False)\n        (linear_path): Linear(in_features=256, out_features=256, bias=False)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (1): GenovaEncoderLayer(\n      (relation): Relation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (linear_edge): Linear(in_features=256, out_features=256, bias=False)\n        (linear_path): Linear(in_features=256, out_features=256, bias=False)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (2): GenovaEncoderLayer(\n      (relation): Relation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (linear_edge): Linear(in_features=256, out_features=256, bias=False)\n        (linear_path): Linear(in_features=256, out_features=256, bias=False)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (3): GenovaEncoderLayer(\n      (relation): Relation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (linear_edge): Linear(in_features=256, out_features=256, bias=False)\n        (linear_path): Linear(in_features=256, out_features=256, bias=False)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (4): GenovaEncoderLayer(\n      (relation): Relation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (linear_edge): Linear(in_features=256, out_features=256, bias=False)\n        (linear_path): Linear(in_features=256, out_features=256, bias=False)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (5): GenovaEncoderLayer(\n      (relation): Relation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (linear_edge): Linear(in_features=256, out_features=256, bias=False)\n        (linear_path): Linear(in_features=256, out_features=256, bias=False)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n  )\n)", "parameters": [["node_encoder.ion_source_embed.weight", [25, 54]], ["node_encoder.charge_embed.weight", [20, 1024]], ["node_encoder.shared_mlp.0.weight", [128, 64]], ["node_encoder.shared_mlp.0.bias", [128]], ["node_encoder.shared_mlp.2.weight", [128]], ["node_encoder.shared_mlp.2.bias", [128]], ["node_encoder.shared_mlp.3.weight", [256, 128]], ["node_encoder.shared_mlp.3.bias", [256]], ["node_encoder.shared_mlp.5.weight", [256]], ["node_encoder.shared_mlp.5.bias", [256]], ["node_encoder.shared_mlp.6.weight", [512, 256]], ["node_encoder.shared_mlp.6.bias", [512]], ["node_encoder.shared_mlp.8.weight", [512]], ["node_encoder.shared_mlp.8.bias", [512]], ["node_encoder.shared_mlp.9.weight", [1024, 512]], ["node_encoder.shared_mlp.9.bias", [1024]], ["node_encoder.fc.1.weight", [1024]], ["node_encoder.fc.1.bias", [1024]], ["node_encoder.fc.2.weight", [1024, 1024]], ["node_encoder.fc.2.bias", [1024]], ["node_encoder.fc.4.weight", [1024]], ["node_encoder.fc.4.bias", [1024]], ["node_encoder.fc.5.weight", [1024, 1024]], ["node_encoder.fc.5.bias", [1024]], ["node_encoder.fc.7.weight", [1024]], ["node_encoder.fc.7.bias", [1024]], ["node_encoder.fc.8.weight", [1024, 1024]], ["node_encoder.fc.8.bias", [1024]], ["path_encoder.edge_type_embed.weight", [50150, 63]], ["path_encoder.edge_pos_embed.weight", [100, 64]], ["path_encoder.dist_embed.weight", [100, 512]], ["path_encoder.mlp.0.weight", [128, 64]], ["path_encoder.mlp.0.bias", [128]], ["path_encoder.mlp.2.weight", [256, 128]], ["path_encoder.mlp.2.bias", [256]], ["path_encoder.mlp.4.weight", [512, 256]], ["path_encoder.mlp.4.bias", [512]], ["path_encoder.fc.0.weight", [512]], ["path_encoder.fc.0.bias", [512]], ["path_encoder.fc.1.weight", [256, 512]], ["path_encoder.fc.1.bias", [256]], ["path_encoder.fc.3.weight", [256, 256]], ["path_encoder.fc.3.bias", [256]], ["edge_encoder.edge_type_embed.weight", [50150, 31]], ["edge_encoder.mlp.0.weight", [64, 32]], ["edge_encoder.mlp.0.bias", [64]], ["edge_encoder.mlp.2.weight", [256, 64]], ["edge_encoder.mlp.2.bias", [256]], ["edge_encoder.fc.0.weight", [256]], ["edge_encoder.fc.0.bias", [256]], ["edge_encoder.fc.1.weight", [256, 256]], ["edge_encoder.fc.1.bias", [256]], ["edge_encoder.fc.3.weight", [256, 256]], ["edge_encoder.fc.3.bias", [256]], ["genova_encoder_layers.0.relation.norm_act.weight", [1024]], ["genova_encoder_layers.0.relation.norm_act.bias", [1024]], ["genova_encoder_layers.0.relation.linear_q.weight", [256, 1024]], ["genova_encoder_layers.0.relation.linear_q.bias", [256]], ["genova_encoder_layers.0.relation.linear_k.weight", [256, 1024]], ["genova_encoder_layers.0.relation.linear_k.bias", [256]], ["genova_encoder_layers.0.relation.linear_v.weight", [1024, 1024]], ["genova_encoder_layers.0.relation.linear_v.bias", [1024]], ["genova_encoder_layers.0.relation.linear_edge.weight", [256, 256]], ["genova_encoder_layers.0.relation.linear_path.weight", [256, 256]], ["genova_encoder_layers.0.relation.talking.weight", [256, 256]], ["genova_encoder_layers.0.relation.output_layer.weight", [1024, 1024]], ["genova_encoder_layers.0.relation.output_layer.bias", [1024]], ["genova_encoder_layers.0.ffn.ln.weight", [1024]], ["genova_encoder_layers.0.ffn.ln.bias", [1024]], ["genova_encoder_layers.0.ffn.pre_ffn_gate.0.weight", [4096, 1024]], ["genova_encoder_layers.0.ffn.pre_ffn.weight", [4096, 1024]], ["genova_encoder_layers.0.ffn.ffnln.weight", [4096]], ["genova_encoder_layers.0.ffn.ffnln.bias", [4096]], ["genova_encoder_layers.0.ffn.post_ffn.weight", [1024, 4096]]], "output_shape": [[8, 128, 1024]], "num_parameters": [1350, 20480, 8192, 128, 128, 128, 32768, 256, 256, 256, 131072, 512, 512, 512, 524288, 1024, 1024, 1024, 1048576, 1024, 1024, 1024, 1048576, 1024, 1024, 1024, 1048576, 1024, 3159450, 6400, 51200, 8192, 128, 32768, 256, 131072, 512, 512, 512, 131072, 256, 65536, 256, 1554650, 2048, 64, 16384, 256, 256, 256, 65536, 256, 65536, 256, 1024, 1024, 262144, 256, 262144, 256, 1048576, 1024, 65536, 65536, 65536, 1048576, 1024, 1024, 1024, 4194304, 4194304, 4096, 4096, 4194304]}, {"name": "decoder", "id": 140244669284416, "class_name": "GenovaDecoder(\n  (genova_decoder_layers): ModuleList(\n    (0): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (1): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (2): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (3): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (4): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (5): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (6): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (7): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (8): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (9): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (10): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n    (11): GenovaDecoderLayer(\n      (self_relation): MaskedSelfRelation(\n        (norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (trans_relation): TransRelation(\n        (q_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (k_norm_act): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (linear_q): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_k): Linear(in_features=1024, out_features=256, bias=True)\n        (linear_v): Linear(in_features=1024, out_features=1024, bias=True)\n        (talking): Linear(in_features=256, out_features=256, bias=False)\n        (output_layer): Linear(in_features=1024, out_features=1024, bias=True)\n      )\n      (ffn): FFNGLU(\n        (ln): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n        (pre_ffn_gate): Sequential(\n          (0): Linear(in_features=1024, out_features=4096, bias=False)\n          (1): GELU()\n        )\n        (pre_ffn): Linear(in_features=1024, out_features=4096, bias=False)\n        (ffnln): LayerNorm((4096,), eps=1e-05, elementwise_affine=True)\n        (post_ffn): Linear(in_features=4096, out_features=1024, bias=False)\n      )\n    )\n  )\n)", "parameters": [["genova_decoder_layers.0.self_relation.norm_act.weight", [1024]], ["genova_decoder_layers.0.self_relation.norm_act.bias", [1024]], ["genova_decoder_layers.0.self_relation.linear_q.weight", [256, 1024]], ["genova_decoder_layers.0.self_relation.linear_q.bias", [256]], ["genova_decoder_layers.0.self_relation.linear_k.weight", [256, 1024]], ["genova_decoder_layers.0.self_relation.linear_k.bias", [256]], ["genova_decoder_layers.0.self_relation.linear_v.weight", [1024, 1024]], ["genova_decoder_layers.0.self_relation.linear_v.bias", [1024]], ["genova_decoder_layers.0.self_relation.talking.weight", [256, 256]], ["genova_decoder_layers.0.self_relation.output_layer.weight", [1024, 1024]], ["genova_decoder_layers.0.self_relation.output_layer.bias", [1024]], ["genova_decoder_layers.0.trans_relation.q_norm_act.weight", [1024]], ["genova_decoder_layers.0.trans_relation.q_norm_act.bias", [1024]], ["genova_decoder_layers.0.trans_relation.k_norm_act.weight", [1024]], ["genova_decoder_layers.0.trans_relation.k_norm_act.bias", [1024]], ["genova_decoder_layers.0.trans_relation.linear_q.weight", [256, 1024]], ["genova_decoder_layers.0.trans_relation.linear_q.bias", [256]], ["genova_decoder_layers.0.trans_relation.linear_k.weight", [256, 1024]], ["genova_decoder_layers.0.trans_relation.linear_k.bias", [256]], ["genova_decoder_layers.0.trans_relation.linear_v.weight", [1024, 1024]], ["genova_decoder_layers.0.trans_relation.linear_v.bias", [1024]], ["genova_decoder_layers.0.trans_relation.talking.weight", [256, 256]], ["genova_decoder_layers.0.trans_relation.output_layer.weight", [1024, 1024]], ["genova_decoder_layers.0.trans_relation.output_layer.bias", [1024]], ["genova_decoder_layers.0.ffn.ln.weight", [1024]], ["genova_decoder_layers.0.ffn.ln.bias", [1024]], ["genova_decoder_layers.0.ffn.pre_ffn_gate.0.weight", [4096, 1024]], ["genova_decoder_layers.0.ffn.pre_ffn.weight", [4096, 1024]], ["genova_decoder_layers.0.ffn.ffnln.weight", [4096]], ["genova_decoder_layers.0.ffn.ffnln.bias", [4096]], ["genova_decoder_layers.0.ffn.post_ffn.weight", [1024, 4096]]], "output_shape": [[8, 9, 1024]], "num_parameters": [1024, 1024, 262144, 256, 262144, 256, 1048576, 1024, 65536, 1048576, 1024, 1024, 1024, 1024, 1024, 262144, 256, 262144, 256, 1048576, 1024, 65536, 1048576, 1024, 1024, 1024, 4194304, 4194304, 4096, 4096, 4194304]}, {"name": "query_node_linear.0", "id": 140244669971088, "class_name": "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)", "parameters": [["weight", [1024]], ["bias", [1024]]], "output_shape": [[8, 9, 1024]], "num_parameters": [1024, 1024]}, {"name": "query_node_linear.1", "id": 140244669970944, "class_name": "Linear(in_features=1024, out_features=1024, bias=True)", "parameters": [["weight", [1024, 1024]], ["bias", [1024]]], "output_shape": [[8, 9, 1024]], "num_parameters": [1048576, 1024]}, {"name": "graph_node_linear.0", "id": 140244669971136, "class_name": "LayerNorm((1024,), eps=1e-05, elementwise_affine=True)", "parameters": [["weight", [1024]], ["bias", [1024]]], "output_shape": [[8, 128, 1024]], "num_parameters": [1024, 1024]}, {"name": "graph_node_linear.1", "id": 140244669971376, "class_name": "Linear(in_features=1024, out_features=1024, bias=True)", "parameters": [["weight", [1024, 1024]], ["bias", [1024]]], "output_shape": [[8, 128, 1024]], "num_parameters": [1048576, 1024]}], "edges": []}