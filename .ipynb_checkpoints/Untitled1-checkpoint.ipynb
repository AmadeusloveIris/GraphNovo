{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d55aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra\n",
    "import wandb\n",
    "import torch\n",
    "from torch.cuda.amp import autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "import genova\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf, open_dict\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0f0bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "hydra.initialize('configs')\n",
    "cfg = hydra.compose('config.yaml')\n",
    "with open_dict(cfg):\n",
    "    cfg.task = 'optimum_path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ff5bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = pd.read_csv('/home/z37mao/genova_dataset_index.csv',low_memory=False,index_col='Spec Index')\n",
    "#spec_header = spec_header[spec_header['MSGP File Name']=='1_3.msgp']\n",
    "#spec_header = spec_header[spec_header['Node Number']<=512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6c3cd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = spec_header[spec_header['MSGP File Name']=='1_3.msgp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0021c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = spec_header[spec_header['Node Number']<=128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68b88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genova.models.Genova(cfg).to(3)\n",
    "ds = genova.data.GenovaDataset(cfg,spec_header=spec_header,dataset_dir_path='/home/z37mao/')\n",
    "sampler = genova.data.GenovaBatchSampler(cfg,torch.device(3),0.9,spec_header,[0,128], model)\n",
    "collate_fn = genova.data.GenovaCollator(cfg)\n",
    "dl = DataLoader(ds, batch_sampler=sampler, collate_fn=collate_fn, pin_memory=True, num_workers=2)\n",
    "dl = genova.data.DataPrefetcher(dl,torch.device(3))\n",
    "loss_fn = torch.nn.KLDivLoss(reduction='batchmean')\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=2e-4)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86294217",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new epoch\n",
      "3.345377576351166\n",
      "2.3930571484565735\n",
      "2.1479326736927034\n",
      "2.0068275344371798\n",
      "new epoch\n",
      "1.9844505786895752\n",
      "2.2607165849208832\n",
      "1.942398247718811\n",
      "1.9117928123474122\n",
      "1.874899628162384\n",
      "new epoch\n",
      "1.9498313665390015\n",
      "2.2033796596527098\n",
      "1.833137058019638\n",
      "1.8242606961727141\n",
      "1.8842390859127045\n",
      "new epoch\n",
      "2.1033236980438232\n",
      "2.088594515323639\n",
      "1.817513861656189\n",
      "1.7799456572532655\n",
      "1.818541531562805\n",
      "new epoch\n",
      "2.072784423828125\n",
      "2.052454866170883\n",
      "1.7916455519199372\n",
      "1.7810451555252076\n",
      "1.7796060848236084\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "loss_cum = 0\n",
    "for epoch in range(epochs):\n",
    "    print('new epoch')\n",
    "    try: print(loss.item())\n",
    "    except: pass\n",
    "    for i, batch in enumerate(dl, start=1):\n",
    "        encoder_input, decoder_input, graph_probability, label, label_mask = batch\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(encoder_input=encoder_input, decoder_input=decoder_input, graph_probability=graph_probability)\n",
    "            output = output.log_softmax(-1)\n",
    "            loss = loss_fn(output[label_mask],label[label_mask])\n",
    "        #break\n",
    "        #print(loss)\n",
    "        loss_cum += loss.item()\n",
    "        if i%100==0:\n",
    "            print(loss_cum/100)\n",
    "            #wandb.log({'loss':loss_cum})\n",
    "            loss_cum = 0\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b618891",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new epoch\n",
      "1.6874823570251465\n",
      "1.7391903650760652\n",
      "1.7110785686969756\n",
      "1.762934627532959\n",
      "1.7356312024593352\n",
      "new epoch\n",
      "1.9749747514724731\n",
      "2.050465053319931\n",
      "1.7123709964752196\n",
      "1.713335702419281\n",
      "1.7026486313343048\n",
      "new epoch\n",
      "1.7378637790679932\n",
      "1.8952631175518035\n",
      "1.6893843185901642\n",
      "1.7154736602306366\n",
      "1.7092554116249083\n",
      "new epoch\n",
      "1.9898345470428467\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2952843/1941827712.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#wandb.log({'loss':loss_cum})\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss_cum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "loss_cum = 0\n",
    "for epoch in range(epochs):\n",
    "    print('new epoch')\n",
    "    try: print(loss.item())\n",
    "    except: pass\n",
    "    for i, batch in enumerate(dl, start=1):\n",
    "        encoder_input, decoder_input, graph_probability, label, label_mask = batch\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(encoder_input=encoder_input, decoder_input=decoder_input, graph_probability=graph_probability)\n",
    "            output = output.log_softmax(-1)\n",
    "            loss = loss_fn(output[label_mask],label[label_mask])\n",
    "        #break\n",
    "        #print(loss)\n",
    "        loss_cum += loss.item()\n",
    "        if i%100==0:\n",
    "            print(loss_cum/100)\n",
    "            #wandb.log({'loss':loss_cum})\n",
    "            loss_cum = 0\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c0a73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "while True:\n",
    "    print('new epoch')\n",
    "    if i == 2: break\n",
    "    for index in sampler:\n",
    "        print(len(index))\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8c6aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
