{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7676521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import genova\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2462c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genova.GenovaEncoder(cfg,bin_classification=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdfca88",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(),'/data/z37mao/genova/save/model_max.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.load('/data/z37mao/genova/save/model_max.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d496c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')\n",
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[np.logical_or(spec_header['Experiment Name']=='Cerebellum',spec_header['Experiment Name']=='HeLa')]\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac481a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "class GenovaCollator(object):\n",
    "    def __init__(self,cfg):\n",
    "        self.cfg = cfg\n",
    "        \n",
    "    def __call__(self,batch):\n",
    "        encoder_records = [record[0] for record in batch]\n",
    "        labels_ori = [record[1] for record in batch]\n",
    "        encoder_input, node_mask = self.encoder_collate(encoder_records)\n",
    "        max_node = max([label.shape[0] for label in labels_ori])\n",
    "        labels = []\n",
    "        for label_ori in labels_ori:\n",
    "            labels.append(pad(label_ori,[0,max_node-label_ori.shape[0]]))\n",
    "        labels = torch.stack(labels)\n",
    "        \n",
    "        return encoder_input, labels, node_mask\n",
    "        \n",
    "    def encoder_collate(self, encoder_records):\n",
    "        node_shape = []\n",
    "        for record in encoder_records: node_shape.append(np.array(record['node_sourceion'].shape))\n",
    "        node_shape = np.array(node_shape).T\n",
    "        max_node = node_shape[0].max()\n",
    "        max_subgraph_node = node_shape[1].max()\n",
    "\n",
    "        node_input = {}\n",
    "        edge_input = {}\n",
    "        rel_input = {}\n",
    "\n",
    "        edge_input['rel_type'] = torch.concat([record['rel_type'] for record in encoder_records])\n",
    "        edge_input['edge_pos'] = torch.concat([record['edge_pos'] for record in encoder_records])\n",
    "        edge_input['rel_error'] = torch.concat([record['rel_error'] for record in encoder_records]).unsqueeze(-1)\n",
    "\n",
    "\n",
    "        node_feat = []\n",
    "        node_sourceion = []\n",
    "        rel_mask = []\n",
    "        dist = []\n",
    "        charge = []\n",
    "        rel_coor_cated = []\n",
    "        node_mask = torch.zeros(len(encoder_records),max_node,dtype=bool)\n",
    "        for i, record in enumerate(encoder_records):\n",
    "            node_num, node_subgraph_node = record['node_sourceion'].shape\n",
    "            node_feat.append(pad(record['node_feat'],[0,0,0,max_subgraph_node-node_subgraph_node,0,max_node-node_num]))\n",
    "            node_sourceion.append(pad(record['node_sourceion'],[0,max_subgraph_node-node_subgraph_node,0,max_node-node_num]))\n",
    "            rel_mask.append(pad(pad(record['rel_mask'],[0,max_node-node_num],value=-float('inf')),[0,0,0,max_node-node_num]))\n",
    "            dist.append(pad(record['dist'],[0,max_node-node_num,0,max_node-node_num]))\n",
    "            charge.append(record['charge'])\n",
    "            rel_coor_cated.append(torch.stack([i*max_node**2+record['rel_coor'][0]*max_node+record['rel_coor'][1],\n",
    "                                               record['rel_coor'][-2]*100+record['rel_coor'][-1]]))\n",
    "            node_mask[i,node_num:] = True\n",
    "\n",
    "        drctn = torch.zeros(max_node,max_node)+torch.tril(2*torch.ones(max_node,max_node),-1)+torch.triu(torch.ones(max_node,max_node),1)\n",
    "        rel_input['drctn'] = drctn.int().unsqueeze(0)\n",
    "        node_input['node_feat'] = torch.stack(node_feat)\n",
    "        node_input['node_sourceion'] = torch.stack(node_sourceion)\n",
    "        rel_input['rel_mask'] = torch.stack(rel_mask).unsqueeze(-1)\n",
    "        edge_input['dist'] = torch.stack(dist)\n",
    "        node_input['charge'] = torch.IntTensor(charge)\n",
    "        edge_input['rel_coor_cated'] = torch.concat(rel_coor_cated,dim=1)\n",
    "        edge_input['batch_num'] = len(encoder_records)\n",
    "        edge_input['max_node'] = max_node\n",
    "        \n",
    "        encoder_input = {'node_input':node_input,'edge_input':edge_input,'rel_input':rel_input}\n",
    "\n",
    "        return encoder_input, node_mask\n",
    "\n",
    "class GenovaDataset(Dataset):\n",
    "    def __init__(self, cfg, *, spec_header, dataset_dir_path):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        #self.dictionary = dictionary\n",
    "        self.spec_header = spec_header\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()\n",
    "        spec_head = dict(self.spec_header.iloc[idx])\n",
    "        with open(os.path.join(self.dataset_dir_path, spec_head['Serialized File Name']),'rb') as f:\n",
    "            f.seek(spec_head['Serialized File Pointer'])\n",
    "            spec = pickle.loads(gzip.decompress(f.read(spec_head['Serialized Data Length'])))\n",
    "        \n",
    "        spec['charge'] = spec_head['Charge']\n",
    "        label = spec.pop('path_label')\n",
    "        label = torch.any(label,-1).long()\n",
    "        edge_type = spec.pop('edge_type')\n",
    "        edge_error = spec.pop('edge_error')\n",
    "        #edge_coor = torch.stack(torch.where(edge_type>0))\n",
    "        #edge_error = edge_error[edge_type>0]\n",
    "        #edge_type = edge_type[edge_type>0]\n",
    "        return spec, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.spec_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42403f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GenovaDataset(cfg, spec_header=small_spec, dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn = GenovaCollator(cfg)\n",
    "dl = DataLoader(ds,batch_size=4,collate_fn=collate_fn,num_workers=4,shuffle=True)\n",
    "model = genova.GenovaEncoder(cfg,bin_classification=True).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),lr=1e-4)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0ce685",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c452c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')\n",
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[spec_header['Experiment Name']=='PXD008844']\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c83fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GenovaDataset(cfg, spec_header=small_spec, dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn = GenovaCollator(cfg)\n",
    "dl = DataLoader(ds,batch_size=4,collate_fn=collate_fn,num_workers=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f0df4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a854307",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "recall = 0\n",
    "precision = 0\n",
    "for i, (encoder_input, labels, node_mask) in enumerate(tqdm(dl),start=1):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    labels = labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            output = model(**encoder_input)\n",
    "    accuracy += (torch.argmax(output[~node_mask],-1)==labels[~node_mask]).sum()/labels[~node_mask].shape[0]\n",
    "    recall += ((torch.argmax(output[~node_mask],-1)==labels[~node_mask])[labels[~node_mask]==1]).sum()/(labels[~node_mask]==1).sum()\n",
    "    precision += ((torch.argmax(output[~node_mask],-1)==labels[~node_mask])[labels[~node_mask]==1]).sum()/(torch.argmax(output[~node_mask],-1)==1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9eed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('accuracy: {}, recall: {}, precision: {}'.format(accuracy.item()/i, recall.item()/i, precision.item()/i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1f5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_input_cuda(encoder_input):\n",
    "    for section_key in encoder_input:\n",
    "        for key in encoder_input[section_key]:\n",
    "            if isinstance(encoder_input[section_key][key],torch.Tensor):\n",
    "                encoder_input[section_key][key] = encoder_input[section_key][key].cuda()\n",
    "    return encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b101d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_detect = 0\n",
    "detect_period = 100\n",
    "for i, (encoder_input, labels, node_mask) in enumerate(dl,start=1):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    labels = labels.cuda()\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        output = model(**encoder_input)\n",
    "        loss = loss_fn(output[~node_mask],labels[~node_mask])\n",
    "    loss_detect+=loss.item()\n",
    "    if i%detect_period==0:\n",
    "        print(loss_detect/detect_period)\n",
    "        loss_detect = 0\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012d22e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a5a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5615eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(rank, world_size):\n",
    "    print(f\"Running DDP checkpoint example on rank {rank}.\")\n",
    "    setup(rank, world_size)\n",
    "\n",
    "    ds = GenovaDataset(cfg, spec_header=small_spec, dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "    collate_fn = GenovaCollator(cfg)\n",
    "    dl = DataLoader(ds,batch_size=4,collate_fn=collate_fn,num_workers=4,shuffle=True)\n",
    "    model = genova.GenovaEncoder(cfg,bin_classification=True).cuda()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(),lr=1e-5)\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    ddp_model = DDP(model, device_ids=[rank])\n",
    "\n",
    "    loss_detect = 0\n",
    "    detect_period = 100\n",
    "    for i, (encoder_input, labels, node_mask) in enumerate(dl,start=1):\n",
    "        encoder_input = encoder_input_cuda(encoder_input)\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(**encoder_input)\n",
    "            loss = loss_fn(output[~node_mask],labels[~node_mask])\n",
    "        loss_detect+=loss.item()\n",
    "        if rank == 0:\n",
    "            if i%detect_period==0:\n",
    "                print(loss_detect/detect_period)\n",
    "                loss_detect = 0\n",
    "            if i%10000==0:\n",
    "                torch.save(ddp_model.state_dict(), '/data/z37mao/save/model_checkpoint.pt')\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    cleanup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f16980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75a7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5db04d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = torch.cuda.device_count()\n",
    "assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n",
    "world_size = n_gpus\n",
    "run(train, world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdc84d8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
