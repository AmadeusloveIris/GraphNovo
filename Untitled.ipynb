{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "188956ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import torch\n",
    "import pickle\n",
    "import json\n",
    "import genova\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "#from genova.data.sampler import GenovaSampler\n",
    "from genova.data.prefetcher import DataPrefetcher\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "import wandb\n",
    "\n",
    "import collections\n",
    "from torch._six import string_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "691eb778",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70aa6d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d92d9715",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = pd.read_csv('/home/z37mao/genova_dataset_index.csv', index_col='Spec Index', low_memory=False)\n",
    "spec_header = spec_header[spec_header['MSGP File Name']=='1_3.msgp']\n",
    "spec_header = spec_header.rename(columns={'MSGP File Name':'Serialized File Name',\n",
    "                                          'MSGP Datablock Pointer':'Serialized File Pointer',\n",
    "                                          'MSGP Datablock Length':'Serialized Data Length'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ea29cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_boarders = [0,128,256,512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acbf94ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from random import choices\n",
    "from torch.utils.data import Sampler\n",
    "\n",
    "class GenovaBatchSampler(Sampler):\n",
    "    \"\"\"Wraps another sampler to yield a mini-batch of indices.\n",
    "\n",
    "    Args:\n",
    "        data_source (Dataset): dataset to sample from\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, cfg, device, gpu_capacity_scaller, spec_header, bin_boarders, shuffle=True) -> None:\n",
    "        super().__init__(data_source=None)\n",
    "        self.cfg = cfg\n",
    "        self.bin_boarders = bin_boarders\n",
    "        self.gpu_capacity = torch.cuda.get_device_properties(device).total_memory*gpu_capacity_scaller\n",
    "        self.shuffle = shuffle\n",
    "        self.spec_header = spec_header\n",
    "        \n",
    "        self.hidden_size = self.cfg['hidden_size']\n",
    "        self.d_relation = self.cfg['encoder']['d_relation']\n",
    "        self.num_layers = self.cfg['encoder']['num_layers']\n",
    "        self.d_node = self.cfg['encoder']['node_encoder']['d_node']\n",
    "        self.d_node_expansion = self.cfg['encoder']['node_encoder']['expansion_factor']\n",
    "        self.edge_expansion = self.cfg['encoder']['edge_encoder']['expansion_factor']\n",
    "        self.edge_d_edge = self.cfg['encoder']['edge_encoder']['d_edge']\n",
    "        self.path_expansion = self.cfg['encoder']['path_encoder']['expansion_factor']\n",
    "        self.path_d_edge = self.cfg['encoder']['path_encoder']['d_edge']\n",
    "\n",
    "        self.node_sparse = 4 * ((29 + self.d_node_expansion) * self.d_node)\n",
    "        self.node = 4 * ((2 * self.d_node_expansion)*self.d_node + 4 * (self.d_node_expansion*self.d_node+self.hidden_size)/2)\n",
    "        \n",
    "        self.relation_matrix = 4 * 7 * self.d_relation * self.num_layers\n",
    "        self.relation_ffn = 4 * (3 * self.d_relation + 13 * self.hidden_size) * self.num_layers + 4*8*self.hidden_size\n",
    "        \n",
    "        self.edge_matrix = 4 * (8*self.edge_d_edge + 2*self.d_relation + 2 * self.edge_expansion*self.edge_d_edge)\n",
    "        self.edge_sparse = 4 * (4 + self.edge_expansion) * self.edge_d_edge\n",
    "        \n",
    "        self.path_matrix = 4 * (8*self.path_d_edge + 2*self.d_relation + 4*self.path_expansion*self.path_d_edge)\n",
    "        self.path_sparse = 4 * (9 + self.path_expansion) * self.path_d_edge\n",
    "\n",
    "    def __iter__(self):\n",
    "        if self.shuffle: self.spec_header = self.spec_header.sample(frac=1)\n",
    "        self.generate_bins()\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.bins_readpointer.sum()==len(self.spec_header): raise StopIteration\n",
    "        bin_index = choices([i for i in range(self.bin_len.size)], \\\n",
    "                            weights=self.bin_len-self.bins_readpointer)[0]\n",
    "        bin = self.bins[bin_index]\n",
    "        max_node = 0\n",
    "        edge_num = 0\n",
    "        path_num = 0\n",
    "        for i in range(self.bins_readpointer[bin_index], len(bin)):\n",
    "            spec_index=bin.iloc[i]\n",
    "            if spec_index['Node Number']>max_node: max_node = spec_index['Node Number']\n",
    "            batch_num = i-self.bins_readpointer[bin_index]+1\n",
    "            edge_num += spec_index['Edge Num']\n",
    "            path_num += spec_index['Relation Num']\n",
    "            node_consumer = self.node_sparse*max_node*batch_num*30 + self.node*max_node*batch_num\n",
    "            edge_consumer = self.edge_matrix*max_node**2*batch_num + self.edge_sparse*edge_num\n",
    "            path_consumer = self.path_matrix*max_node**2*batch_num + self.path_sparse*path_num\n",
    "            relation_cosumer = self.relation_matrix*max_node**2*batch_num + self.relation_ffn*max_node*batch_num\n",
    "            theo = node_consumer+edge_consumer+path_consumer+relation_cosumer\n",
    "            if theo>self.gpu_capacity:\n",
    "                index = bin.iloc[self.bins_readpointer[bin_index]:i].index\n",
    "                self.bins_readpointer[bin_index] = i\n",
    "                return index\n",
    "        index = bin.iloc[self.bins_readpointer[bin_index]:].index\n",
    "        self.bins_readpointer[bin_index] = len(bin)\n",
    "        return index\n",
    "        \n",
    "\n",
    "    def generate_bins(self):\n",
    "        if self.shuffle: self.spec_header.sample(frac=1)\n",
    "        self.bins = [self.spec_header[np.logical_and(self.spec_header['Node Number']>self.bin_boarders[i], \\\n",
    "            self.spec_header['Node Number']<=self.bin_boarders[i+1])] for i in range(len(self.bin_boarders)-1)]\n",
    "        self.bin_len = np.array([len(bin_index) for bin_index in self.bins])\n",
    "        self.bins_readpointer = np.zeros(len(self.bin_boarders)-1,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6139e285",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = spec_header[spec_header['Node Number']<=256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c76bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenovaCollator(object):\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        node_inputs = [record['node_input'] for record in batch]\n",
    "        path_inputs = [record['rel_input'] for record in batch]\n",
    "        edge_inputs = [record['edge_input'] for record in batch]\n",
    "        node_labels = [record['graph_label'] for record in batch]\n",
    "        \n",
    "        node_shape = np.array([node_input['node_sourceion'].shape for node_input in node_inputs]).T\n",
    "        max_node = node_shape[0].max()\n",
    "        max_subgraph_node = node_shape[1].max()\n",
    "        batch_num = len(batch)\n",
    "        \n",
    "        node_input = self.node_collate(node_inputs, max_node, max_subgraph_node)\n",
    "        path_input = self.path_collate(path_inputs, max_node, node_shape)\n",
    "        edge_input = self.edge_collate(edge_inputs, max_node)\n",
    "        rel_mask = self.rel_collate(node_shape, max_node)\n",
    "        node_labels, node_mask = self.nodelabel_collate(node_labels, max_node)\n",
    "        \n",
    "        encoder_input = {'node_input':node_input,'path_input':path_input,\n",
    "                         'edge_input':edge_input,'rel_mask':rel_mask}\n",
    "        labels = {'node_labels':node_labels, 'node_mask':node_mask}\n",
    "        \n",
    "        return encoder_input, labels\n",
    "\n",
    "    def node_collate(self, node_inputs, max_node, max_subgraph_node):\n",
    "        node_feat = []\n",
    "        node_sourceion = []\n",
    "        charge = torch.IntTensor([node_input['charge'] for node_input in node_inputs])\n",
    "        for node_input in node_inputs:\n",
    "            node_num, node_subgraph_node = node_input['node_sourceion'].shape\n",
    "            node_feat.append(pad(node_input['node_feat'], \n",
    "                                 [0, 0, 0, max_subgraph_node - node_subgraph_node, 0, max_node - node_num]))\n",
    "            node_sourceion.append(pad(node_input['node_sourceion'], \n",
    "                                      [0, max_subgraph_node - node_subgraph_node, 0, max_node - node_num]))\n",
    "        return {'node_feat':torch.stack(node_feat),'node_sourceion':torch.stack(node_sourceion),'charge':charge}\n",
    "    \n",
    "    def path_collate(self, path_inputs, max_node, node_shape):\n",
    "        rel_type = torch.concat([path_input['rel_type'] for path_input in path_inputs]).squeeze(-1)\n",
    "        rel_error = torch.concat([path_input['rel_error'] for path_input in path_inputs])\n",
    "        rel_coor = torch.concat([pad(path_input['rel_coor'],[1,0],value=i) for i, path_input in enumerate(path_inputs)]).T\n",
    "        rel_coor_cated = torch.stack([rel_coor[0]*max_node**2+rel_coor[1]*max_node+rel_coor[2],\n",
    "                                      rel_coor[-2]*self.cfg.preprocessing.edge_type_num+rel_coor[-1]])\n",
    "        \n",
    "        rel_pos = torch.concat([path_input['rel_coor'][:,-2] for path_input in path_inputs])\n",
    "        dist = torch.stack([pad(path_input['dist'],[0,max_node-node_shape[0,i],0,max_node-node_shape[0,i]]) for i, path_input in enumerate(path_inputs)])\n",
    "        \n",
    "        return {'rel_type':rel_type,'rel_error':rel_error,\n",
    "                'rel_pos':rel_pos,'dist':dist,\n",
    "                'rel_coor_cated':rel_coor_cated,\n",
    "                'max_node': max_node, 'batch_num': len(path_inputs)}\n",
    "        \n",
    "        \n",
    "    def edge_collate(self, edge_inputs, max_node):\n",
    "        rel_type = torch.concat([edge_input['edge_type'] for edge_input in edge_inputs]).squeeze(-1)\n",
    "        rel_error = torch.concat([edge_input['edge_error'] for edge_input in edge_inputs])\n",
    "        rel_coor = torch.concat([pad(edge_input['edge_coor'],[1,0],value=i) for i, edge_input in enumerate(edge_inputs)]).T\n",
    "        rel_coor_cated = torch.stack([rel_coor[0]*max_node**2+rel_coor[1]*max_node+rel_coor[2],\n",
    "                                      rel_coor[-1]])\n",
    "        \n",
    "        return {'rel_type':rel_type,'rel_error':rel_error,\n",
    "                'rel_coor_cated':rel_coor_cated, \n",
    "                'max_node': max_node, 'batch_num': len(edge_inputs)}\n",
    "        \n",
    "    def rel_collate(self, node_shape, max_node):\n",
    "        rel_masks = []\n",
    "        for i in node_shape[0]:\n",
    "            rel_mask = -np.inf * torch.ones(max_node,max_node,1)\n",
    "            rel_mask[:,:i] = 0\n",
    "            rel_masks.append(rel_mask)\n",
    "        rel_masks = torch.stack(rel_masks)\n",
    "        return rel_masks\n",
    "    \n",
    "    def nodelabel_collate(self, node_labels_temp, max_node):\n",
    "        node_mask = torch.ones(len(node_labels_temp),max_node).bool()\n",
    "        node_labels = []\n",
    "        for i, node_label in enumerate(node_labels_temp):\n",
    "            node_mask[i, node_label.shape[0]:] = 0\n",
    "            node_labels.append(pad(node_label,[0,max_node-node_label.shape[0]]))\n",
    "        node_labels = torch.stack(node_labels)\n",
    "        return node_labels, node_mask\n",
    "    \n",
    "\n",
    "class GenovaDataset(Dataset):\n",
    "    def __init__(self, cfg, *, spec_header, dataset_dir_path):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.spec_header = spec_header\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()\n",
    "        spec_head = dict(self.spec_header.loc[idx])\n",
    "        with open(os.path.join(self.dataset_dir_path, spec_head['Serialized File Name']), 'rb') as f:\n",
    "            f.seek(spec_head['Serialized File Pointer'])\n",
    "            spec = pickle.loads(gzip.decompress(f.read(spec_head['Serialized Data Length'])))\n",
    "\n",
    "        spec['node_input']['charge'] = spec_head['Charge']\n",
    "        spec.pop('node_mass')\n",
    "        spec['graph_label'] = torch.any(spec['graph_label'], -1).long()\n",
    "        return spec\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.spec_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13032bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GenovaDataset(cfg, spec_header=spec_header, dataset_dir_path='/home/z37mao/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc047c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\", 1)\n",
    "torch.cuda.set_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45465e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = GenovaCollator(cfg)\n",
    "sampler = GenovaBatchSampler(cfg,device,0.9,spec_header,bin_boarders)\n",
    "dl = DataLoader(ds,batch_sampler=sampler,collate_fn=collate_fn,num_workers=2,pin_memory=True)\n",
    "dl = DataPrefetcher(dl,device,non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33a99cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dl:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d00aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genova.GenovaEncoder(cfg, bin_classification=True).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b973891c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4)\n",
    "scaler = GradScaler()\n",
    "print(torch.cuda.memory_allocated())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5530248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_detect = 0\n",
    "for i, (encoder_input, labels) in enumerate(dl,start=1):\n",
    "    optimizer.zero_grad()\n",
    "    with autocast():\n",
    "        output = model(**encoder_input)\n",
    "        #print(torch.cuda.memory_allocated())\n",
    "        loss = loss_fn(output[labels['node_mask']], labels['node_labels'][labels['node_mask']])\n",
    "    loss_detect += loss.item()\n",
    "    max_node = encoder_input['edge_input']['max_node']\n",
    "    batch_num = encoder_input['edge_input']['batch_num']\n",
    "    edge_num = len(encoder_input['edge_input']['rel_type'])\n",
    "    path_num = len(encoder_input['path_input']['rel_type'])\n",
    "    \n",
    "    node_consumer = a.node_sparse*max_node*batch_num*encoder_input['node_input']['node_feat'].shape[-2] + a.node*max_node*batch_num\n",
    "    edge_consumer = a.edge_matrix*max_node**2*batch_num + a.edge_sparse*edge_num\n",
    "    path_consumer = a.path_matrix*max_node**2*batch_num + a.path_sparse*path_num\n",
    "    relation_cosumer = a.relation_matrix*max_node**2*batch_num + a.relation_ffn*max_node*batch_num\n",
    "    theo = node_consumer+edge_consumer+path_consumer+relation_cosumer\n",
    "    theo = (theo+47562752*4)*0.75\n",
    "    real = torch.cuda.memory_allocated()\n",
    "    print(theo/real)\n",
    "    if theo/real<0.6 or theo/real>1.7: \n",
    "        print(theo/real, max_node, edge_num, path_num, encoder_input['node_input']['node_feat'].shape[-2])\n",
    "    #break\n",
    "    scaler.scale(loss).backward()\n",
    "    scaler.step(optimizer)\n",
    "    scaler.update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc3dfcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_node = 128\n",
    "batch_num = 32\n",
    "edge_num = 1e6\n",
    "path_num = 5e5\n",
    "\n",
    "node_consumer = a.node_sparse*max_node*batch_num*30 + a.node*max_node*batch_num\n",
    "edge_consumer = a.edge_matrix*max_node**2*batch_num + a.edge_sparse*edge_num\n",
    "path_consumer = a.path_matrix*max_node**2*batch_num + a.path_sparse*path_num\n",
    "relation_cosumer = a.relation_matrix*max_node**2*batch_num + a.relation_ffn*max_node*batch_num\n",
    "theo = node_consumer+edge_consumer+path_consumer+relation_cosumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9f49bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "theo/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87bf4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg['encoder']['d_relation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1abc6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input['node_input']['node_feat'].shape[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903620f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "1527211008/4*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990084a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "1145408256+45208880*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564cd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "728486896/1213900288"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04634297",
   "metadata": {},
   "outputs": [],
   "source": [
    "18844*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481cfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input['edge_input']['rel_type'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d60232",
   "metadata": {},
   "outputs": [],
   "source": [
    "if encoder_input['path_input']['rel_pos']!=None:\n",
    "    print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2683db",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = nn.Embedding(50150,54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92583f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input['edge_input']['rel_type'].squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c424a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(encoder_input['edge_input']['rel_type'].squeeze(-1)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b1b361",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input['edge_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27383439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_input_cuda(encoder_input, device):\n",
    "    for section_key in encoder_input:\n",
    "        for key in encoder_input[section_key]:\n",
    "            if isinstance(encoder_input[section_key][key], torch.Tensor):\n",
    "                encoder_input[section_key][key] = encoder_input[section_key][key].to(device)\n",
    "    return encoder_input\n",
    "\n",
    "\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "local_rank = int(os.environ['LOCAL_RANK'])\n",
    "\n",
    "if local_rank == 0:\n",
    "    wandb.init(project=\"Genova\", entity=\"rxnatalie\")\n",
    "\n",
    "torch.cuda.set_device(local_rank)\n",
    "dist.init_process_group(backend='nccl')  # nccl是GPU设备上最快、最推荐的后端\n",
    "\n",
    "# 构造模型\n",
    "device = torch.device(\"cuda\", local_rank)\n",
    "\n",
    "ds = GenovaDataset(cfg, spec_header=small_spec, dataset_dir_path='./pretrain_data_sparse/')\n",
    "# num_train_samples = 2000\n",
    "# ds = Subset(ds, np.arange(num_train_samples))\n",
    "\n",
    "collate_fn = GenovaCollator(cfg)\n",
    "sampler = GenovaSampler(ds, cfg, 13)\n",
    "dl = DataLoader(ds, batch_sampler=sampler, collate_fn=collate_fn, num_workers=1)\n",
    "# dl = DataLoader(ds,batch_size=4,collate_fn=collate_fn,num_workers=1,shuffle=True)\n",
    "model = genova.GenovaEncoder(cfg, bin_classification=True).to(local_rank)\n",
    "model = DDP(model, device_ids=[local_rank])\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=2e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "CHECKPOINT_PATH = './save/sampler_test/model_max.pt'\n",
    "# #checkpoint = torch.load(CHECKPOINT_PATH,map_location = {'cuda:%d' % 0: 'cuda:%d' % local_rank})['model_state_dict']\n",
    "# checkpoint = torch.load(CHECKPOINT_PATH,map_location = {'cuda:%d' % 0: 'cuda:%d' % local_rank})\n",
    "# if list(model.state_dict().keys())[0].startswith('module'):\n",
    "#     #model.load_state_dict(checkpoint)\n",
    "#     model.load_state_dict(OrderedDict([('module.'+key, v) for key, v in checkpoint.items()]))\n",
    "# else:\n",
    "#     #model.load_state_dict(OrderedDict([(key[7:], v) for key, v in checkpoint.items()]))\n",
    "#     model.load_state_dict(checkpoint)\n",
    "\n",
    "loss_detect = 0\n",
    "min_loss = 10000\n",
    "detect_period = 50\n",
    "accuracy = 0\n",
    "recall = 0\n",
    "precision = 0\n",
    "for epoch in range(2):\n",
    "    print('Epoch:', epoch)\n",
    "    for i, (encoder_input, labels, node_mask) in enumerate(dl, start=1):\n",
    "        if i % 50 == 0:\n",
    "            print('Sample:', i)\n",
    "        encoder_input = encoder_input_cuda(encoder_input, device)\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(**encoder_input)\n",
    "            loss = loss_fn(output[~node_mask], labels[~node_mask])\n",
    "        if local_rank == 0:\n",
    "            output = torch.argmax(output[~node_mask], -1)\n",
    "            labels = labels[~node_mask]\n",
    "            accuracy += (output == labels).sum() / labels.shape[0]\n",
    "            recall += ((output == labels)[labels == 1]).sum() / (labels == 1).sum()\n",
    "            precision += ((output == labels)[labels == 1]).sum() / (output == 1).sum()\n",
    "            loss_detect += loss.item()\n",
    "            if i % detect_period == 0:\n",
    "                wandb.log({\"loss\": loss_detect / detect_period,\n",
    "                           \"accuracy\": accuracy / detect_period,\n",
    "                           \"recall\": recall / detect_period,\n",
    "                           \"precision\": precision / detect_period}\n",
    "                          )\n",
    "                torch.save({'model_state_dict': model.state_dict(),\n",
    "                            'optimizer_state_dict': optimizer.state_dict()}, CHECKPOINT_PATH)\n",
    "                loss_detect, accuracy, recall, precision = 0, 0, 0, 0\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f292c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9984b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label = spec.pop('graph_label')\n",
    "print(label.shape)\n",
    "label = torch.any(label, -1).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e1c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec['rel_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ebd7544",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds[0]['node_input']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f76a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_input[0]['node_feat'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
