{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bcca83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.distributed as dist\n",
    "import torch.multiprocessing as mp\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c75fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dee862",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gpus = torch.cuda.device_count()\n",
    "assert n_gpus >= 2, f\"Requires at least 2 GPUs to run, but got {n_gpus}\"\n",
    "world_size = n_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f077615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import genova\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')\n",
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[np.logical_or(spec_header['Experiment Name']=='Cerebellum',spec_header['Experiment Name']=='HeLa')]\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]\n",
    "\n",
    "import os\n",
    "import gzip\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "class GenovaCollator(object):\n",
    "    def __init__(self,cfg):\n",
    "        self.cfg = cfg\n",
    "        \n",
    "    def __call__(self,batch):\n",
    "        encoder_records = [record[0] for record in batch]\n",
    "        labels_ori = [record[1] for record in batch]\n",
    "        encoder_input, node_mask = self.encoder_collate(encoder_records)\n",
    "        max_node = max([label.shape[0] for label in labels_ori])\n",
    "        labels = []\n",
    "        for label_ori in labels_ori:\n",
    "            labels.append(pad(label_ori,[0,max_node-label_ori.shape[0]]))\n",
    "        labels = torch.stack(labels)\n",
    "        \n",
    "        return encoder_input, labels, node_mask\n",
    "        \n",
    "    def encoder_collate(self, encoder_records):\n",
    "        node_shape = []\n",
    "        for record in encoder_records: node_shape.append(np.array(record['node_sourceion'].shape))\n",
    "        node_shape = np.array(node_shape).T\n",
    "        max_node = node_shape[0].max()\n",
    "        max_subgraph_node = node_shape[1].max()\n",
    "\n",
    "        node_input = {}\n",
    "        edge_input = {}\n",
    "        rel_input = {}\n",
    "\n",
    "        edge_input['rel_type'] = torch.concat([record['rel_type'] for record in encoder_records])\n",
    "        edge_input['edge_pos'] = torch.concat([record['edge_pos'] for record in encoder_records])\n",
    "        edge_input['rel_error'] = torch.concat([record['rel_error'] for record in encoder_records]).unsqueeze(-1)\n",
    "\n",
    "\n",
    "        node_feat = []\n",
    "        node_sourceion = []\n",
    "        rel_mask = []\n",
    "        dist = []\n",
    "        charge = []\n",
    "        rel_coor_cated = []\n",
    "        node_mask = torch.zeros(len(encoder_records),max_node,dtype=bool)\n",
    "        for i, record in enumerate(encoder_records):\n",
    "            node_num, node_subgraph_node = record['node_sourceion'].shape\n",
    "            node_feat.append(pad(record['node_feat'],[0,0,0,max_subgraph_node-node_subgraph_node,0,max_node-node_num]))\n",
    "            node_sourceion.append(pad(record['node_sourceion'],[0,max_subgraph_node-node_subgraph_node,0,max_node-node_num]))\n",
    "            rel_mask.append(pad(pad(record['rel_mask'],[0,max_node-node_num],value=-float('inf')),[0,0,0,max_node-node_num]))\n",
    "            dist.append(pad(record['dist'],[0,max_node-node_num,0,max_node-node_num]))\n",
    "            charge.append(record['charge'])\n",
    "            rel_coor_cated.append(torch.stack([i*max_node**2+record['rel_coor'][0]*max_node+record['rel_coor'][1],\n",
    "                                               record['rel_coor'][-2]*100+record['rel_coor'][-1]]))\n",
    "            node_mask[i,node_num:] = True\n",
    "\n",
    "        drctn = torch.zeros(max_node,max_node)+torch.tril(2*torch.ones(max_node,max_node),-1)+torch.triu(torch.ones(max_node,max_node),1)\n",
    "        rel_input['drctn'] = drctn.int().unsqueeze(0)\n",
    "        node_input['node_feat'] = torch.stack(node_feat)\n",
    "        node_input['node_sourceion'] = torch.stack(node_sourceion)\n",
    "        rel_input['rel_mask'] = torch.stack(rel_mask).unsqueeze(-1)\n",
    "        edge_input['dist'] = torch.stack(dist)\n",
    "        node_input['charge'] = torch.IntTensor(charge)\n",
    "        edge_input['rel_coor_cated'] = torch.concat(rel_coor_cated,dim=1)\n",
    "        edge_input['batch_num'] = len(encoder_records)\n",
    "        edge_input['max_node'] = max_node\n",
    "        \n",
    "        encoder_input = {'node_input':node_input,'edge_input':edge_input,'rel_input':rel_input}\n",
    "\n",
    "        return encoder_input, node_mask\n",
    "\n",
    "class GenovaDataset(Dataset):\n",
    "    def __init__(self, cfg, *, spec_header, dataset_dir_path):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        #self.dictionary = dictionary\n",
    "        self.spec_header = spec_header\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()\n",
    "        spec_head = dict(self.spec_header.iloc[idx])\n",
    "        with open(os.path.join(self.dataset_dir_path, spec_head['Serialized File Name']),'rb') as f:\n",
    "            f.seek(spec_head['Serialized File Pointer'])\n",
    "            spec = pickle.loads(gzip.decompress(f.read(spec_head['Serialized Data Length'])))\n",
    "        \n",
    "        spec['charge'] = spec_head['Charge']\n",
    "        label = spec.pop('path_label')\n",
    "        label = torch.any(label,-1).long()\n",
    "        edge_type = spec.pop('edge_type')\n",
    "        edge_error = spec.pop('edge_error')\n",
    "        #edge_coor = torch.stack(torch.where(edge_type>0))\n",
    "        #edge_error = edge_error[edge_type>0]\n",
    "        #edge_type = edge_type[edge_type>0]\n",
    "        return spec, label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.spec_header)\n",
    "    \n",
    "ds = GenovaDataset(cfg, spec_header=small_spec, dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn = GenovaCollator(cfg)\n",
    "dl = DataLoader(ds,batch_size=4,collate_fn=collate_fn,num_workers=4,shuffle=True)\n",
    "model = genova.GenovaEncoder(cfg,bin_classification=True).cuda()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(),lr=1e-4)\n",
    "scaler = GradScaler()\n",
    "\n",
    "def encoder_input_cuda(encoder_input):\n",
    "    for section_key in encoder_input:\n",
    "        for key in encoder_input[section_key]:\n",
    "            if isinstance(encoder_input[section_key][key],torch.Tensor):\n",
    "                encoder_input[section_key][key] = encoder_input[section_key][key].cuda()\n",
    "    return encoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942db29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup(rank, world_size):\n",
    "    os.environ['MASTER_ADDR'] = 'localhost'\n",
    "    os.environ['MASTER_PORT'] = '12355'\n",
    "\n",
    "    # initialize the process group\n",
    "    dist.init_process_group(\"gloo\", rank=rank, world_size=world_size)\n",
    "\n",
    "def cleanup():\n",
    "    dist.destroy_process_group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41178a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9d2edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_demo(demo_fn, world_size):\n",
    "    mp.spawn(demo_fn,\n",
    "             args=(world_size,),\n",
    "             nprocs=world_size,\n",
    "             join=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
