{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "956aa111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import genova\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler as GradScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a22bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genova/utils/dictionary') as f:\n",
    "    dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9890863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')\n",
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[np.logical_or(spec_header['Experiment Name']=='Cerebellum',spec_header['Experiment Name']=='HeLa')]\n",
    "#spec_header = spec_header[spec_header['Node Number']<=512]\n",
    "#spec_header = spec_header[spec_header['path_matrix_dense_num']<=1e6]\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]\n",
    "dataset = genova.data.GenovaDataset(cfg,dictionary=dictionary,spec_header=small_spec,dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn  = genova.data.GenovaCollator(cfg,mode='train')\n",
    "dl = DataLoader(dataset,batch_size=16,collate_fn=collate_fn,num_workers=8,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b5f3012",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')\n",
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[spec_header['Experiment Name']=='PXD008844']\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]\n",
    "dataset = genova.data.GenovaDataset(cfg,dictionary=dictionary,spec_header=small_spec,dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn  = genova.data.GenovaCollator(cfg,mode='train')\n",
    "dl = DataLoader(dataset,batch_size=16,collate_fn=collate_fn,num_workers=8,shuffle=True)\n",
    "model = genova.models.Genova(cfg).cuda()\n",
    "#torch.save(model.state_dict(),'/data/z37mao/save/GenovaPrototype.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce694521",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b46ba3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('/data/z37mao/save/Genova_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec939fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_state_dict = OrderedDict([(k[7:],v) for k,v in checkpoint['model_state_dict'].items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57aa7e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_temp = []\n",
    "for key, v in checkpoint.items():\n",
    "    if key.split('.')[0] != 'output_ffn': checkpoint_temp.append(('encoder.'+key, v))\n",
    "for key, v in model.state_dict().items():\n",
    "    if key.split('.')[0] != 'encoder': checkpoint_temp.append((key, v))\n",
    "checkpoint = OrderedDict(checkpoint_temp)\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e370c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.encoder.parameters():\n",
    "    param.requires_grad = False\n",
    "optimizer = optim.AdamW(model.parameters(),lr=1e-5)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "833adc4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder_input_cuda(encoder_input):\n",
    "    for section_key in encoder_input:\n",
    "        for key in encoder_input[section_key]:\n",
    "            if isinstance(encoder_input[section_key][key],torch.Tensor):\n",
    "                if encoder_input[section_key][key].dtype == torch.float32:\n",
    "                    encoder_input[section_key][key] = encoder_input[section_key][key].cuda().half()\n",
    "                else:\n",
    "                    encoder_input[section_key][key] = encoder_input[section_key][key].cuda()\n",
    "    return encoder_input\n",
    "\n",
    "def decoder_input_cuda(decoder_input):\n",
    "    for key in decoder_input:\n",
    "        if isinstance(decoder_input[key],torch.Tensor):\n",
    "            decoder_input[key] = decoder_input[key].cuda()\n",
    "    return decoder_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46965fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_detect = 0\n",
    "detect_period = 200\n",
    "for epoch in range(5):\n",
    "    for i, (encoder_input, decoder_input, labels) in enumerate(dl,start=1):\n",
    "        encoder_input = encoder_input_cuda(encoder_input)\n",
    "        decoder_input = decoder_input_cuda(decoder_input)\n",
    "        labels = labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        with autocast():\n",
    "            output = model(encoder_input=encoder_input,decoder_input=decoder_input)\n",
    "            loss = loss_fn(output[labels!=0],labels[labels!=0])\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "        #torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b525c774",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict':model.state_dict(),\n",
    "            'optim_state_dict':optimizer.state_dict()},\n",
    "            'save/model_large_{}.pt'.format(datetime.strftime(datetime.now(),'%Y-%m-%d_%H-%M')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbbed45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = genova.models.Genova(cfg).cuda()\n",
    "checkpoint = torch.load('save/model_large_2022-02-22_16-51.pt')\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b587db",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = pd.read_csv('/data/z37mao/genova/pretrain_data_sparse/genova_psm.csv',index_col='index')\n",
    "spec_header = spec_header[spec_header['Experiment Name']=='PXD008844']\n",
    "small_spec = spec_header[spec_header['Node Number']<=256]\n",
    "dataset = genova.data.GenovaDataset(cfg,dictionary=dictionary,spec_header=small_spec,dataset_dir_path='/data/z37mao/genova/pretrain_data_sparse/')\n",
    "collate_fn  = genova.data.GenovaCollator(cfg,mode='train')\n",
    "dl = DataLoader(dataset,batch_size=1,collate_fn=collate_fn,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c745f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e6e8e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_detect = 0\n",
    "recall_detect = 0\n",
    "recall_pep_detect = 0\n",
    "predict = []\n",
    "label = []\n",
    "for i, (encoder_input, decoder_input, labels) in enumerate(dl,start=1):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    decoder_input = decoder_input_cuda(decoder_input)\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            output = model(encoder_input=encoder_input,decoder_input=decoder_input)\n",
    "            predict.append([reverse_dict[i.item()] for i in torch.argmax(output,-1)[0,:-1].cpu()])\n",
    "            label.append([reverse_dict[i.item()] for i in labels[0,:-1].cpu()])\n",
    "    #loss_detect+=loss.item()\n",
    "    #recall_detect+=recall.item()\n",
    "    #recall_pep_detect+=recall_pep.item()\n",
    "    if i==2000: break\n",
    "print(loss_detect/i,recall_detect/i,recall_pep_detect/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfec1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8971690",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734b86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_dict = {dictionary[aa]:aa for aa in dictionary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f6ea58",
   "metadata": {},
   "outputs": [],
   "source": [
    "[reverse_dict[i.item()] for i in torch.argmax(output,-1)[0,:-1].cpu()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13138c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.argmax(output,-1)==labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb73b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e7d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_detect = 0\n",
    "recall_detect = 0\n",
    "recall_pep_detect = 0\n",
    "for i, (encoder_input, decoder_input, labels) in enumerate(dl,start=1):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    decoder_input = decoder_input_cuda(decoder_input)\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            output = model(encoder_input=encoder_input,decoder_input=decoder_input)\n",
    "            loss = loss_fn(output[labels!=0],labels[labels!=0])\n",
    "            recall = (torch.argmax(output[labels!=0],-1)==labels[labels!=0]).sum()/labels[labels!=0].shape[0]\n",
    "            recall_pep = torch.all(torch.argmax(output,-1)==labels).sum()\n",
    "    loss_detect+=loss.item()\n",
    "    recall_detect+=recall.item()\n",
    "    recall_pep_detect+=recall_pep.item()\n",
    "    if i==2000: break\n",
    "print(loss_detect/i,recall_detect/i,recall_pep_detect/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e3c639",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "759b0085",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.23 GiB (GPU 0; 15.78 GiB total capacity; 2.49 GiB already allocated; 2.67 GiB free; 2.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_351087/1906560320.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrecall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Genova/genova/models/genova.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, decoder_input, encoder_input)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0m不是变量\u001b[0m\u001b[0;31m。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \"\"\"\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mencoder_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mpepseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mpepseq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_ffn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpepseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Genova/genova/models/genova_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, node_input, edge_input, rel_input)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mnode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mnode_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0medge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0medge_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mlast_relation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Genova/genova/modules/edge_encoder.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, rel_type, rel_error, edge_pos, dist, rel_coor_cated, batch_num, max_node)\u001b[0m\n\u001b[1;32m     85\u001b[0m                                             \u001b[0msparse_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_node\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmax_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                                             is_sorted=True)\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_sparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_node\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelation\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mdist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mrelation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelation\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrelation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch_sparse/reduce.py\u001b[0m in \u001b[0;36mmax\u001b[0;34m(src, dim)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch_sparse/reduce.py\u001b[0m in \u001b[0;36mreduction\u001b[0;34m(src, dim, reduce)\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msegment_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrowptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch_scatter/segment_csr.py\u001b[0m in \u001b[0;36msegment_csr\u001b[0;34m(src, indptr, out, reduce)\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msegment_min_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'max'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msegment_max_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/genova_torch/lib/python3.9/site-packages/torch_scatter/segment_csr.py\u001b[0m in \u001b[0;36msegment_max_csr\u001b[0;34m(src, indptr, out)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m ) -> Tuple[torch.Tensor, torch.Tensor]:\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorch_scatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msegment_max_csr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.23 GiB (GPU 0; 15.78 GiB total capacity; 2.49 GiB already allocated; 2.67 GiB free; 2.55 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "loss_detect = 0\n",
    "recall_detect = 0\n",
    "for i, (encoder_input, decoder_input, labels) in enumerate(dl,start=1):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    decoder_input = decoder_input_cuda(decoder_input)\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        output = model(encoder_input=encoder_input,decoder_input=decoder_input)\n",
    "        loss = loss_fn(output[labels!=0],labels[labels!=0])\n",
    "        recall = (torch.argmax(output[labels!=0],-1)==labels[labels!=0]).sum()/labels[labels!=0].shape[0]\n",
    "    break\n",
    "    loss_detect+=loss.item()\n",
    "    recall_detect+=recall.item()\n",
    "    if i==2000: break\n",
    "print(loss_detect/i,recall_detect/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc9626",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (encoder_input, decoder_input, labels) in enumerate(dl,start=1):\n",
    "    encoder_input = encoder_input_cuda(encoder_input)\n",
    "    decoder_input = decoder_input_cuda(decoder_input)\n",
    "    labels = labels.cuda()\n",
    "    with torch.no_grad():\n",
    "        with autocast():\n",
    "            output = model(encoder_input=encoder_input,decoder_input=decoder_input)\n",
    "            #loss = loss_fn(output[labels!=0],labels[labels!=0])\n",
    "            #recall = (torch.argmax(output[labels!=0],-1)==labels[labels!=0]).sum()/labels[labels!=0].shape[0]\n",
    "    print(torch.argmax(output,-1).cpu().numpy())\n",
    "    print(labels.cpu().numpy())\n",
    "    print()\n",
    "    if i==10: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7900bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.argmax(output,-1).cpu().numpy())\n",
    "print(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1d771a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8020c65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
