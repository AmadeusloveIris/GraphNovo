{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d55aa7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import genova\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from omegaconf import OmegaConf\n",
    "from genova.utils.BasicClass import Residual_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ff5bc04",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header = pd.read_csv('/home/z37mao/genova_dataset_index.csv',low_memory=False,index_col='Spec Index')\n",
    "spec_header = spec_header[spec_header['MSGP File Name']=='1_3.msgp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d35b53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load('configs/genova_dda_light.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47adee3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spec_header = spec_header[np.logical_and(spec_header['Node Number']<=512,spec_header['Node Number']>256)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad169bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_spec_header = spec_header[spec_header['Node Number']<=128]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1e24b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler = genova.data.GenovaBatchSampler(cfg,0,0.9,test_spec_header,[0,128,256,512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4302fbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampler.gpu_capacity = 80*1024**3*0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aad6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sampler:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda5a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import torch\n",
    "import pickle\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class GenovaDataset(Dataset):\n",
    "    def __init__(self, cfg, *, spec_header, dataset_dir_path, aa_datablock_dict = None):\n",
    "        super().__init__()\n",
    "        self.cfg = cfg\n",
    "        self.spec_header = spec_header\n",
    "        self.dataset_dir_path = dataset_dir_path\n",
    "        if cfg.task == 'sequence_generation' or cfg.task == 'optimum_path_sequence': \n",
    "            assert aa_datablock_dict\n",
    "            self.aa_datablock_dict = aa_datablock_dict\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx): idx = idx.tolist()\n",
    "        spec_head = dict(self.spec_header.loc[idx])\n",
    "        with open(os.path.join(self.dataset_dir_path, spec_head['MSGP File Name']), 'rb') as f:\n",
    "            f.seek(spec_head['MSGP Datablock Pointer'])\n",
    "            spec = pickle.loads(gzip.decompress(f.read(spec_head['MSGP Datablock Length'])))\n",
    "\n",
    "        spec['node_input']['charge'] = spec_head['Charge']\n",
    "        graph_label = spec.pop('graph_label').T\n",
    "        graph_label = graph_label[graph_label.any(-1)]\n",
    "        node_mass = spec.pop('node_mass')\n",
    "        seq = spec_head['Annotated Sequence']\n",
    "        if self.cfg.task == 'node_classification':\n",
    "            spec['graph_label'] = torch.any(graph_label, 0).long()\n",
    "            return spec\n",
    "        \n",
    "        elif self.cfg.task == 'optimum_path_sequence':\n",
    "            raise NotImplementedError\n",
    "            \n",
    "        elif self.cfg.task == 'sequence_generation':\n",
    "            target = {}\n",
    "            seq_blocks = self.seq2seqblock(seq, graph_label)\n",
    "            target['tgt'] = seq_blocks\n",
    "            target['trans_mask'] = self.trans_mask_sequence_generation(seq_blocks, node_mass)\n",
    "            return spec, target\n",
    "        \n",
    "        elif self.cfg.task == 'optimum_path':\n",
    "            trans_mask = torch.Tensor(self.trans_mask_optimum_path(graph_label))\n",
    "            graph_probability = torch.Tensor(self.graph_probability_gen(graph_label))\n",
    "            tgt = {}\n",
    "            tgt['tgt'] = graph_probability[:-1]\n",
    "            tgt['trans_mask'] = trans_mask\n",
    "            return spec, tgt, graph_probability[1:]\n",
    "            \n",
    "    def graph_probability_gen(self, graph_label):\n",
    "        graph_probability = graph_label/graph_label.sum(-1).unsqueeze(1)\n",
    "        return graph_probability\n",
    "    \n",
    "    def trans_mask_sequence_generation(self,seq_blocks,node_mass):\n",
    "        seq_mass = np.array([Residual_seq(seq_block.replace('L','I')).mass for seq_block in seq_blocks]).cumsum()\n",
    "        trans_mask = torch.zeros((seq_mass.size,node_mass.size))\n",
    "        trans_mask[0,0] = -float('inf')\n",
    "        for i, board in enumerate(node_mass.searchsorted(seq_mass+0.02,side='right')[:-1],start=1):\n",
    "            trans_mask[i,:board] = -float('inf')\n",
    "        return trans_mask\n",
    "    \n",
    "    def trans_mask_optimum_path(self,graph_label):\n",
    "        graph_label = graph_label[1:-1]\n",
    "        trans_mask = torch.zeros((graph_label.shape[0]+1,graph_label.shape[1]))\n",
    "        trans_mask[0,0] = -float('inf')\n",
    "        for i, node_pos in enumerate(graph_label,start=1):\n",
    "            trans_mask[i,:torch.where(node_pos)[0].max().item()] = -float('inf')\n",
    "        return trans_mask\n",
    "    \n",
    "    def seq2seqblock(self, seq, graph_label):\n",
    "        seq_block = []\n",
    "        for i, combine_flag in enumerate(~graph_label.any(-1)[1:]):\n",
    "            if combine_flag:\n",
    "                if 'combine_start_index' not in locals():\n",
    "                    combine_start_index = i\n",
    "            else:\n",
    "                try:\n",
    "                    if i+1-combine_start_index>6: seq_block.append('X')\n",
    "                    else:\n",
    "                        seq_block.append(seq[combine_start_index:i+1])\n",
    "                        del(combine_start_index)\n",
    "                except:\n",
    "                    seq_block.append(seq[i])\n",
    "        return seq_block\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.spec_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da81d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenovaCollator(object):\n",
    "    def __init__(self, cfg):\n",
    "        self.cfg = cfg\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        if self.cfg.task == 'optimum_path':\n",
    "            spec = [record[0] for record in batch]\n",
    "            tgt = [record[1] for record in batch]\n",
    "            label = [record[2] for record in batch]\n",
    "            encoder_input = self.encoder_collate(spec)\n",
    "            decoder_input, graph_probability = self.decoder_collate(tgt)\n",
    "            label, label_mask = self.label_collate(label)\n",
    "            return encoder_input, decoder_input, graph_probability, label, label_mask\n",
    "        \n",
    "        elif self.cfg.task == 'sequence_generation':\n",
    "            raise NotImplementedError\n",
    "        \n",
    "        elif self.cfg.task == 'node_classification':\n",
    "            raise NotImplementedError\n",
    "    \n",
    "    def decoder_collate(self, decoder_input):\n",
    "        if self.cfg.task == 'optimum_path':\n",
    "            tgts_list = [record['tgt'] for record in decoder_input]\n",
    "            trans_mask_list = [record['trans_mask'] for record in decoder_input]\n",
    "            shape_list = np.array([tgt.shape for tgt in tgts_list])\n",
    "            seqdblock_max = shape_list[:,0].max()\n",
    "            node_max = shape_list[:,1].max()\n",
    "            \n",
    "            graph_probability = []\n",
    "            trans_mask = []\n",
    "            for i in range(len(tgts_list)):\n",
    "                graph_probability.append(pad(tgts_list[i],[0,node_max-shape_list[i,1],\n",
    "                                                           0,seqdblock_max-shape_list[i,0]]))\n",
    "                trans_mask_temp = pad(trans_mask_list[i],[0,node_max-shape_list[i,1]],\n",
    "                                      value=-float('inf'))\n",
    "                trans_mask.append(pad(trans_mask_temp,[0,0,0,seqdblock_max-shape_list[i,0]]))\n",
    "            graph_probability = torch.stack(graph_probability)\n",
    "            decoder_input = {'trans_mask': torch.stack(trans_mask).unsqueeze(-1), \n",
    "                             'self_mask': (-float('inf')*torch.ones(seqdblock_max,seqdblock_max)) \\\n",
    "                             .triu(diagonal=1).unsqueeze(-1)}\n",
    "            return decoder_input, graph_probability\n",
    "            \n",
    "    def label_collate(self, labels):\n",
    "        if self.cfg.task == 'optimum_path':\n",
    "            shape_list = np.array([label.shape for label in labels])\n",
    "            seqdblock_max = shape_list[:,0].max()\n",
    "            node_max = shape_list[:,1].max()\n",
    "            result = []\n",
    "            result_pading_mask = torch.ones(len(labels),seqdblock_max,dtype=bool)\n",
    "            for i, label in enumerate(labels):\n",
    "                result_pading_mask[i, label.shape[0]:] = 0\n",
    "                label = pad(label,[0,node_max-label.shape[1],0,seqdblock_max-label.shape[0]])\n",
    "                result.append(label)\n",
    "            return torch.stack(result), result_pading_mask\n",
    "    \n",
    "    def encoder_collate(self, spec):\n",
    "        node_inputs = [record['node_input'] for record in spec]\n",
    "        path_inputs = [record['rel_input'] for record in spec]\n",
    "        edge_inputs = [record['edge_input'] for record in spec]\n",
    "        \n",
    "        node_shape = np.array([node_input['node_sourceion'].shape for node_input in node_inputs]).T\n",
    "        max_node = node_shape[0].max()\n",
    "        max_subgraph_node = node_shape[1].max()\n",
    "        \n",
    "        node_input = self.node_collate(node_inputs, max_node, max_subgraph_node)\n",
    "        path_input = self.path_collate(path_inputs, max_node, node_shape)\n",
    "        edge_input = self.edge_collate(edge_inputs, max_node)\n",
    "        rel_mask = self.rel_collate(node_shape, max_node)\n",
    "        encoder_input = {'node_input':node_input,'path_input':path_input,\n",
    "                         'edge_input':edge_input,'rel_mask':rel_mask}\n",
    "        return encoder_input\n",
    "\n",
    "    def node_collate(self, node_inputs, max_node, max_subgraph_node):\n",
    "        node_feat = []\n",
    "        node_sourceion = []\n",
    "        charge = torch.IntTensor([node_input['charge'] for node_input in node_inputs])\n",
    "        for node_input in node_inputs:\n",
    "            node_num, node_subgraph_node = node_input['node_sourceion'].shape\n",
    "            node_feat.append(pad(node_input['node_feat'], \n",
    "                                 [0, 0, 0, max_subgraph_node - node_subgraph_node, 0, max_node - node_num]))\n",
    "            node_sourceion.append(pad(node_input['node_sourceion'], \n",
    "                                      [0, max_subgraph_node - node_subgraph_node, 0, max_node - node_num]))\n",
    "        return {'node_feat':torch.stack(node_feat),'node_sourceion':torch.stack(node_sourceion),'charge':charge}\n",
    "    \n",
    "    def path_collate(self, path_inputs, max_node, node_shape):\n",
    "        rel_type = torch.concat([path_input['rel_type'] for path_input in path_inputs]).squeeze(-1)\n",
    "        rel_error = torch.concat([path_input['rel_error'] for path_input in path_inputs])\n",
    "        rel_coor = torch.concat([pad(path_input['rel_coor'],[1,0],value=i) for i, path_input in enumerate(path_inputs)]).T\n",
    "        rel_coor_cated = torch.stack([rel_coor[0]*max_node**2+rel_coor[1]*max_node+rel_coor[2],\n",
    "                                      rel_coor[-2]*self.cfg.preprocessing.edge_type_num+rel_coor[-1]])\n",
    "        \n",
    "        rel_pos = torch.concat([path_input['rel_coor'][:,-2] for path_input in path_inputs])\n",
    "        dist = torch.stack([pad(path_input['dist'],[0,max_node-node_shape[0,i],0,max_node-node_shape[0,i]]) for i, path_input in enumerate(path_inputs)])\n",
    "        \n",
    "        return {'rel_type':rel_type,'rel_error':rel_error,\n",
    "                'rel_pos':rel_pos,'dist':dist,\n",
    "                'rel_coor_cated':rel_coor_cated,\n",
    "                'max_node': max_node, 'batch_num': len(path_inputs)}\n",
    "        \n",
    "        \n",
    "    def edge_collate(self, edge_inputs, max_node):\n",
    "        rel_type = torch.concat([edge_input['edge_type'] for edge_input in edge_inputs]).squeeze(-1)\n",
    "        rel_error = torch.concat([edge_input['edge_error'] for edge_input in edge_inputs])\n",
    "        rel_coor = torch.concat([pad(edge_input['edge_coor'],[1,0],value=i) for i, edge_input in enumerate(edge_inputs)]).T\n",
    "        rel_coor_cated = torch.stack([rel_coor[0]*max_node**2+rel_coor[1]*max_node+rel_coor[2],\n",
    "                                      rel_coor[-1]])\n",
    "        \n",
    "        return {'rel_type':rel_type,'rel_error':rel_error,\n",
    "                'rel_coor_cated':rel_coor_cated, \n",
    "                'max_node': max_node, 'batch_num': len(edge_inputs)}\n",
    "        \n",
    "    def rel_collate(self, node_shape, max_node):\n",
    "        rel_masks = []\n",
    "        for i in node_shape[0]:\n",
    "            rel_mask = -np.inf * torch.ones(max_node,max_node,1)\n",
    "            rel_mask[:,:i] = 0\n",
    "            rel_masks.append(rel_mask)\n",
    "        rel_masks = torch.stack(rel_masks)\n",
    "        return rel_masks\n",
    "    \n",
    "    def nodelabel_collate(self, node_labels_temp, max_node):\n",
    "        node_mask = torch.ones(len(node_labels_temp),max_node).bool()\n",
    "        node_labels = []\n",
    "        for i, node_label in enumerate(node_labels_temp):\n",
    "            node_mask[i, node_label.shape[0]:] = 0\n",
    "            node_labels.append(pad(node_label,[0,max_node-node_label.shape[0]]))\n",
    "        node_labels = torch.stack(node_labels)\n",
    "        return node_labels, node_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9346c06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = GenovaDataset(cfg,spec_header=spec_header,dataset_dir_path='/home/z37mao/')\n",
    "collator = GenovaCollator(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94abdfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = collator(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517429dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "result[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e33c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = [ds[index] for index in spec_header.index[0:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaf156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = [record[1] for record in batch]\n",
    "labels = [record[2] for record in batch]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a8f833",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_list = np.array([label.shape for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4b0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6938c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad(label,[0,node_max-label.shape[1],0,seqdblock_max-label.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d8775",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_max-label.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392454b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqdblock_max = shape_list[:,0].max()\n",
    "node_max = shape_list[:,1].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36a90df",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "for label in labels:\n",
    "    label = pad(label,[0,node_max-label.shape[1],0,seqdblock_max-label.shape[0]])\n",
    "    result.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e14b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.stack(result).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb34ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tgt[1]['tgt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d8bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt[0]['tgt'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5154ab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec, tgt, graph_probability = ds['Cerebellum:F12.2:11100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240c1b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bf6c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(graph_label)[0][1:]-np.where(graph_label)[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d787c41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(graph_label)[0][1:]-np.where(graph_label)[0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b23070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=np.where(~graph_label)[0]\n",
    "for i, flag in enumerate(np.where(~graph_label)[0]):\n",
    "    if flag:\n",
    "        min_index = i\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a5381d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f0449",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_blocks = target['tgt']\n",
    "seq_mass = np.array([Residual_seq(seq_block.replace('L','I')).mass for seq_block in seq_blocks]).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b56262",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d65741",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bc08da",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array([1,1,1,1,1,1,0],dtype=bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9da52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2seqblock(self, ):\n",
    "    seq_block = []\n",
    "    for i, combine_flag in enumerate(~spec['graph_label'].any(0)[1:]):\n",
    "        if combine_flag:\n",
    "            if 'combine_start_index' not in locals():\n",
    "                combine_start_index = i\n",
    "        else:\n",
    "            try:\n",
    "                seq_block.append(seq[combine_start_index:i+1])\n",
    "                del(combine_start_index)\n",
    "            except:\n",
    "                seq_block.append(seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13700d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb83a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt = []\n",
    "for i, combine_flag in enumerate(~spec['graph_label'].any(0)[1:]):\n",
    "    if combine_flag: \n",
    "        try:\n",
    "            combine_start_index\n",
    "        except:\n",
    "            combine_start_index = i\n",
    "    else:\n",
    "        try:\n",
    "            tgt.append(seq[combine_start_index:i+1])\n",
    "            del(combine_start_index)\n",
    "        except:\n",
    "            tgt.append(seq[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba1f759",
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ad5fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[4:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ecc3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_start_index = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0adc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_start_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2a944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq['memory_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cae90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_label = spec['graph_label'].T\n",
    "graph_propobility = graph_label/torch.where(graph_label.sum(-1)==0,1,graph_label.sum(-1)).unsqueeze(1)\n",
    "graph_propobility = graph_propobility[torch.any(graph_label,-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ad7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_propobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24756970",
   "metadata": {},
   "outputs": [],
   "source": [
    "a={'fsdaf':'afds'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0db8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'fsdaf' in a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b388d970",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_mass = genova.utils.BasicClass.Residual_seq(seq[:-1].replace('L','I')).step_mass-0.02\n",
    "memory_mask = np.zeros((seq_mass.size+1,spec['node_mass'].size))\n",
    "for i, board in enumerate(spec['node_mass'].searchsorted(seq_mass),start=1):\n",
    "    memory_mask[i,:board] = -float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3b37c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_mask = memory_mask[np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7081c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec['node_mass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1951171",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.repeat(memory_mask,cfg.decoder.num_heads,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211acdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(spec['graph_label'][1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216d1511",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(graph_label[0])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ba6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec['graph_label']/torch.where(spec['graph_label'].sum(-1)==0,1,spec['graph_label'].sum(-1)).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52828850",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec['graph_label'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0a5e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, board in enumerate(spec['node_mass'].searchsorted(a),start=1):\n",
    "    b[i,:board] = -float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f8a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hydra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a03de",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91579219",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=genova.utils.BasicClass.Residual_seq(seq[:-1].replace('L','I')).step_mass-0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4364e146",
   "metadata": {},
   "outputs": [],
   "source": [
    "genova.utils.BasicClass.Residual_seq(seq.replace('L','I')).step_mass-0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32edd45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len('DLVILLYETALLSSGFSLEDPQTHANR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d31966",
   "metadata": {},
   "outputs": [],
   "source": [
    "genova.utils.seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef75774b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header.loc['Cerebellum:F12.12:46468']['Annotated Sequence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596ebeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d2ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(spec_header.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9471c283",
   "metadata": {},
   "outputs": [],
   "source": [
    "genova.utils.BasicClass.Residual_seq('DLVLLLYDTALSSSGFSLFDPQTHNNR'.replace('L','I')).step_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a5f6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "genova.utils.BasicClass.Residual_seq('DLVILLYETALLSSGFSLEDPQTHANR'.replace('L','I')).step_mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b85f882",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/z37mao/genova_new/Cerebellum.mgfs', 'rb') as f:\n",
    "    f.seek(spec_head['MSGP Datablock Pointer'])\n",
    "    spec = pickle.loads(gzip.decompress(f.read(spec_head['MSGP Datablock Length'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed9d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c29bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bc680a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('genova/utils/dictionary') as f:\n",
    "    dictionary = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d6578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "\n",
    "all_edge_mass = []\n",
    "aalist = Residual_seq.output_aalist()\n",
    "for num in range(1,7):\n",
    "    for i in combinations_with_replacement(aalist,num):\n",
    "        all_edge_mass.append(Residual_seq(i).mass)\n",
    "all_edge_mass = np.unique(np.array(all_edge_mass))\n",
    "print(len(all_edge_mass))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20734dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "from itertools import combinations_with_replacement\n",
    "from genova.utils.BasicClass import Residual_seq\n",
    "\n",
    "aa_candidate_datablock_temp = {}\n",
    "aalist = Residual_seq.output_aalist()\n",
    "for num in range(1,7):\n",
    "    for i in combinations_with_replacement(aalist,num):\n",
    "        mass = Residual_seq(i).mass\n",
    "        if len(i)==1: aa_db = i[0]\n",
    "        else: aa_db = '[{}]'.format(''.join(i))\n",
    "        if mass in aa_candidate_datablock_temp: aa_candidate_datablock_temp[mass].append(aa_db)\n",
    "        else: aa_candidate_datablock_temp[mass] = [aa_db]\n",
    "\n",
    "aa_candidate_datablock = OrderedDict()\n",
    "for aa_db_mass in sorted(list(aa_candidate_datablock_temp.keys())):\n",
    "    aa_candidate_datablock[aa_db_mass] = aa_candidate_datablock_temp[aa_db_mass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5d3159",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(aa_candidate_datablock.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78bb6187",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_candidate_datablock = OrderedDict()\n",
    "for aa_db_mass in sorted(list(aa_candidate_datablock_temp.keys())):\n",
    "    aa_candidate_datablock[aa_db_mass] = aa_candidate_datablock_temp[aa_db_mass]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c52928",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_candidate_datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1ed5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a47f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "for aa_db_mass in aa_candidate_datablock.keys():\n",
    "    print(aa_db_mass)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7057f6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=list(aa_candidate_datablock.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c4f5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db258b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_candidate_datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f8d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "20214.1205 in aa_datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cf5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "aa_datablock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d704fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'[ab][cd]'.split('[')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2debd78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "1/3*np.log(1/3)-1/3*np.log(0.98)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f18018",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genova.utils.BasicClass import Composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0095f807",
   "metadata": {},
   "outputs": [],
   "source": [
    "Composition(' ').mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b797f920",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.rand([32,32,32,256])+(-float('inf')*torch.ones((32,32,32))).triu(diagonal=1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0806682b",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=(-float('inf')*torch.ones((32,32))).triu(diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e664bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.rand(4,32,32,25)+torch.rand(32,32).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ee6de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ln = nn.LayerNorm(4).cuda()\n",
    "relu = nn.ReLU(inplace=True)\n",
    "a=torch.rand(64,128,128,256).cuda()\n",
    "for i in trange(1000):\n",
    "    with autocast():\n",
    "        relu(a)\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff9fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(256,256).cuda()\n",
    "a=torch.rand(64,128,128,256).cuda()\n",
    "for i in trange(1000):\n",
    "    with autocast():\n",
    "        linear(a)\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d2e8e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "ln = nn.LayerNorm(256).cuda()\n",
    "a=torch.rand(64,128,128,256).cuda()\n",
    "for i in trange(1000):\n",
    "    with autocast():\n",
    "        ln(a)\n",
    "        torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b00d11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genova_torch",
   "language": "python",
   "name": "genova_torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
